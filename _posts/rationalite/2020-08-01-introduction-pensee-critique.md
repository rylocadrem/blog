---
layout: post
title:  "[BROUILLON] Introduction à la pensée critique"
excerpt: Une introduction aux principes fondamentaux de la pensée critique, à la rationalité et la méthode scientifique.
date:   2020-08-01 8:30:00 +0200
categories: rationalite
redirect_from: /rationalite/2020/07/16/introduction-pensee-critique
hidden: 1
---

Cet article est probablement le plus fondamental de ceux que j'ai écrit jusqu'ici. Il fait une introduction aux principes fondamentaux de la pensée critique, à la rationalité et la méthode scientifique, qui sont cruciaux pour bien raisonner, comprendre le monde, décortiquer les affirmations et ne pas se faire manipuler.

La pensée critique, que je défini juste après, est non seulement utile pour réfléchir sur des sujets scientifiques, mais aussi politiques, sociétaux, etc. Elle est également un excellent outil dans le cadre de la foi, pour analyser avec une rigueur méthodique toute affirmation de ceux qui voudraient nous imposer leurs dogmes.

Cet article comporte une première partie théorique qui présente les concept et les outils fondamentaux, puis une seconde partie pratique avec des exercices et des applications sur des cas concrets.

{% include wip-warning.html %}

Table des matières :

* Table des matières (ligne remplacée automatiquement, cf. <https://kramdown.gettalong.org/converter/html.html#toc>)
{:toc}

## Définitions

Avant de rentrer dans le coeur du sujets, précisons quelques termes centraux.

### Pensée critique

Le concept de *pensée critique* n'est pas toujours clairement établi et son périmètre paur varier d'une considération à l'autre. On parle aussi parfois d'*esprit critique*.

Dans cet article, et en général, je me rattache à la définition donnée par Robert H. Ennis[^ennis_1], car elle est à la fois assez large tout en étant relativement exhaustive :

> Pensée raisonnable et réflexive orientée vers une décision quant à ce qu'il faut croire ou faire.

Cette définition dégage plusieurs points importants :

* *Raisonnable*, donc conforme aux facultés intellectuelles ordonnées de jugement, de discernement, de compréhension, etc.[^tlfi_raison]
* *Réflexive*, donc examinant en profondeur son sujet et étudiant ses propres mécanismes.[^tlfi_reflexion]
* Orientée vers une *décision*, c'est à dire dont l'objectif n'est pas la pensée en elle-même.

Voici encore quelques autres définitions de la *pensée critique*, qui peuvent éclairer certains aspects.

Celle de Matthew Lipman[^lipman_1] :

> Pensée qui facilite le jugement en s'appuyant sur des critères, en s'auto-corrigeant et en étant perméable au contexte.

Celle de John E. McPeck[^mcpeck_1] :

> Habileté et propension à s'engager dans une activité avec un scepticisme réflexif.

Nous préciserons tout cela et verrons ce que ça implique dans la suite de cet article.

### Rationalité

La rationalité peut être définie simplement comme étant[^tlfi_rationnel] :

> Le caractère de ce qui est conforme à la raison.

Ou, comme le définit Eliezer Yudkowsky[^rationality_less_wrong] :

> La rationalité est l'art de penser de manière à produire des croyances précises et prendre de bonnes décisions.

On peut ainsi distinguer deux concepts de rationalité :

1. **La rationalité épistémique** : améliorer systématiquement la précision de ses croyances
2. **La rationalité instrumentale** : atteindre systématiquement ses objectifs

La rationalité *épistémique* est la recherche systématique de la vérité, c'est-à-dire la construction de schémas mentaux qui correspondent le plus possible à la réalité.

La rationalité *instrumentale* est l'accomplissement systématique de ses objectifs, c'est-à-dire le choix des actions qui mènent aux conséquences désirées.

La pensée critique est donc une démarche rationnelle, au sens épistémique comme instrumental.

NB : ne pas confondre avec le *rationalisme* qui est une doctrine philosophique selon laquelle la raison seule suffirait à produire des connaissances certaines, par oppisition à l'empirisme qui prone l'acquisition des connaissances via l'observation et l'expérience.

### Scepticisme scientifique

La notion de *scepticisme scientifique* ou *scepticisme rationnel* peut être définie comme suit[^wiki_scepticisme] :

> Position épistémologique et attitude de doute cartésien vis-à-vis des allégations non étayées par des preuves empiriques.

Il s'agit dont d'une posture de doute *à priori*, s'appuyant sur la pensée critique et la méthode zététique. On peut dire que le scepticisme scientifique est donc un choix rationnel, au sens épistémique comme instrumental.

### Zététique

Un terme fortement lié au concept de pensée critique est celui de *zététique*. Le mot vient du grec ζητητικός (zētētikós) qui signifie "qui aime chercher".

Aujourd'hui, le terme désigne "l'art du doute". Comme le dit Richard Monvoisin[^monvoisin_these] :

> Le terme zététique, au sens moderne, désigne la méthode, la démarche critique proprement dite, là où le scepticisme offre la posture épistémologique. D'une manière un peu simpliste, nous tendons à dire que le scepticisme est la posture philosophique dont la zététique est le bras outillé.

Et il précise également :

> Ainsi le terme moderne zététique revêt-il désormais deux aspects :
>
> * l'un fonctionnel : elle est la démarche scientifique d'investigation des phénomènes extraordinaires, des
prétentions étranges et des théories discutables, analysées selon un scepticisme méthodologique ouvert et une philosophie rationaliste matérialiste.
> * l'un didactique : elle est la panoplie de tous les moyens intellectuels mis en œuvre pour amener l'apprenant à développer l'esprit critique vis-à-vis de toute thèse de type scientifique.

Ainsi, la zététique est donc l'ensemble des méthodes utiles à la pensée critique.

### Science

Le mot *science* désigne parfois des concepts qui ne sont pas pertinents dans notre contexte. Il peut par exemple désigner l'ensemble des connaissances, la communauté scientifique, l'usage politique de la science, etc.

Dans le cadre de cet article, je donne cette définition :

> Démarche intellectuelle structurée visant à produire des affirmations objectivables s'approchant le plus possible de la réalité.

## Réflexions préalables

### Raison vs émotions

Il existe un mythe tenace selon lequel raison et émotions seraient opposées, ou encore que plus une personne serait rationnelle plus elle serait privée d'émotions, froides, calculatrice et incapable d'être créative ou d'apprécier la beauté.

<img class="picture" src="{{ site.baseurl }}/assets/images/rational.jpg" alt="Raison vs Émotions" />

Est-ce légitime d'opposer émotions, créativité et spontanéité à rationalité ? D'opposer scientifique à artiste ? D'associer riguer de pensée avec rigidité de caractère ?

Il existe pourtant de nombreux exemples de personnes qui démontrent le contraire. Citons par exemple :

* **Léonard de Vinci**, peintre, sculpteur, architecte, philosophe, ingénieur, organisateur de fêtes[^herodote_vinci], poète, musicien, botaniste, etc.
* **Beatrix Potter**, écrivaine et naturaliste[^armitt_potter]
* **Samuel Morse**, ingénieur et peintre[^nga_morse]
* **Hedy Lamarr**, actrice de cinéma et inventrice[^ms_lamarr]
* **Brian May**,  musicien, chanteur, compositeur et astrophysicien[^sa_queen]

Nous sommes, bien heureusement, capables de changer de mode de pensée selon les situations et même de combiner plusieurs modes de pensée (par exemple quand on écrit de la fiction : créativité des dialogues et du style avec rigueur des règles de la langue et cohérence de l'histoire).

En outre, d'un point de vue scientifique, les émotions qui sont des états biologiques associés au système nerveux[^panksepp] [^damasio] [^ekman] provoqués par des déclencheurs neurophysiologiques[^cabanac] [^emory] associés à des pensées, des sentiments, des réponses comportementales, etc. Elles sont donc provoquées par des éléments réels et peuvent être une source d'information utile pour une prise de décision.[^pfister]

Les émotions sont certes une grande source de biais cognitifs mais peuvent aussi être utilisées lors d'une réflexion. Comment le disent Alan Kirman, Pierre Livet et Miriam Teschl[^kirman] :

> Les résultats de recherches psychologiques et neurologiques montrent que les émotions et les états affectifs ne sont pas seulement des sources de jugements biaisés, mais peuvent également servir de fonctions essentielles conduisant à des choix plus appropriés.

Cependant les émotions ne sont pes des reflets fiables de la réalité, sont facilement manupulables et peuvent induire une persévérance à long terme dans de mauvaises décisions.[^andrade]

En résumé, émotions et rationalité ne s'opposent pas. Les émotions peuvent être des indices à utiliser avec une grande parcimonie lors d'un processus de réflexion.

### Trop rationnel ?

J'ai souvent entendu des remarques du genre : "il ne faut pas être trop rationnel, sinon tu ne peux plus t'émerveiller" ou "il ne faut pas être trop rationnel, tout vouloir calculer plutôt que de suivre son instinct, sinon tu rates des opportunités", etc.

Que peut-on y répondre ? C'est très simple !

Si mon objectif est de pouvoir être émerveillé, par exemple par un film ou un spectacle de prestidigitation, alors il est parfaitement rationnel (au sens instrumental) de na pas chercher à comprendre les trucages et effets spéciaux. De même, si mon objectif est de saisir des opportunités, il est parfaitement rationnel de suivre son instinct. Être rationnel c'est aussi utiliser le mode de pensée le plus adapté à la situation.

Rappelons-nous toujours les deux concepts de rationalité :

1. **La rationalité épistémique** : améliorer systématiquement la précision de ses croyances
2. **La rationalité instrumentale** : atteindre systématiquement ses objectifs

### Idées fausses sur la rationalité

Je réfute ici brièvement cinq idées fausses couramment exprimées à propos de la rationalité, deux desquelles ont été abordées juste avant.

#### 1. Être rationnel c'est s'attendre à ce que les autres soient rationnels

En réalité être rationnel c'est avoir un modèle représantant le réel le plus fidèlement possible, avoir une idée la plus vraie possible de la réalité. Or si en réalité tout le monde n'est pas rationnel, ou l'est à différents degrés, il est rationnel d'adapter notre représentation du monde en conséquence.

#### 2. Être rationnel signifie ne jamais prendre de décision avant d'avoir toutes les informations

Encore une fois, agir de façon rationnelle c'est maximiser nos chances d'atteindre nos objectifs. Or si notre objectif est d'accomplir une tâche de manière efficace (dans les délais, sans rater d'opportunités, etc.) il est rationnel de prendre des risques et d'avancer avant d'avoir tous les éléments. Être rationnel, c'est ne pas se limiter à considérer les informations mais aussi les risques, le temps, les conséquences, etc.

Voici un exemple d'illustration donné par le psychologue Gerd Gigerenzer[^gigerenzer] :

> Imaginez un homme essayant de trouver une femme à épouser. Il devrait examiner les probabilités des diverses conséquences du mariage avec chacune d'elles. Après de nombreuses années de recherche, il découvrirait probablement que son choix final avait déjà épousé une autre personne qui n'a pas fait ces calculs, et en est tombé amoureux.

Dans cet exemple, attendre d'avoir toutes les informatiosn est clairement contreprodictif au regard de l'objectif, c'est-à-dire irrationnel.

#### 3. Être rationnel signifie ne jamais se fier à l'intuition

On peut distinguer deux "modes de fonctionnement" du cerveau, appelés *système 1* et *système 2* (ou parfois *système implicite* et *système explicite*)[^kahneman] [^evans] :

**Le système 1**, intuitif, nous permet de faire des jugements rapides et automatiques en utilisant des raccourcis (c'est-à-dire des heuristiques) qui sont généralement bons la plupart du temps, tout en nécessitant très peu de temps et d'attention.

**Le système 2**, délibératif, nous permet de faire des choses comme le raisonnement abstrait et la pensée hypothétique et de créer des modèles qui expliquent des événements inattendus. Le système 2 a tendance à faire mieux lorsque vous avez plus de ressources et plus de temps et pire lorsque vous disposez de peu de temps.

Les deux systèmes se disputent le contrôle de nos inférences et de nos actions.

Voici une expérience réalisée par Shane Frederick qui illustre ces deux systèmes[^frederick]. Il pose une série de trois questions ayant une réponse issue du système 1, fausse, "qui vient immédiatement à l'esprit" et une autre issue du système 2, juste, qui nécessite quelques instants de réflexion :

* Une batte et une balle coûtent 1,10 $ au total. La batte coûte 1,00 $ de plus que la balle. Combien coûte la balle ?
* S'il faut à 5 machines 5 minutes pour créer 5 produits, combien de temps faudrait-il à 100 machines pour créer 100 produits ?
* Sur un lac il y a une zone de nénuphars. Chaque jour, la zone double de taille. S'il faut 48 jours pour que la zone couvre tout le lac, combien de temps faudrait-il pour qu'elle recouvre la moitié du lac ?

Les réponses issues du système 1, fausses, sont :

* 0,10 $
* 100 minutes
* 24 jours

Les réponses issues du système 2, correctes, sont :

* 0,05 $
* 5 minutes
* 47 jours

Ainsi, comme le résume Julia Galef[^galef_vulcan] :

> Votre *système 1* est sujet aux biais, et il est également incroyablement puissant. Notre intuition a tendance à bien faire avec les décisions d'achat ou d'autres choix concernant notre vie personnelle. Le système 1 est également très puissant pour un expert. Les grands maîtres d'échecs peuvent jeter un coup d'œil sur un échiquier et dire "échec ét mat en trois coups", à cause du temps et des efforts mentaux consacrés à jouer aux échecs et à construire une base de connaissances mentales à ce sujet.
>
> L'intuition peut être mauvaise et moins fiable lorsqu'elle est basée sur quelque chose qui n'est pas pertinent pour la tâche à accomplir ou lorsque vous ne disposez pas de connaissances spécialisées sur le sujet.
>
> La principale chose à retenir est que les deux systèmes ont des forces et des faiblesses, et que la rationalité consiste à trouver le meilleur chemin — en utilisant les deux systèmes au bon moment — vers la rationalité épistémique et instrumentale.

#### 4. Être rationnel signifie ne pas avoir d'émotions

Tout d'abord, comme l'explique Julia Galef[^galef_vulcan] :

> Les émotions sont nécessaires pour établir nos objectifs, la rationalité n'a aucune valeur normative sans elles.

En effet, atteindre nos objectifs efficacement suppose que nous ayons des objectifs. Et ceux-ci sont subjectifs.

De plus, comme vu précédemment, il est absolument possible de choisir d'être émotif ou non, et à différents degrés, selon les situations. En outre les émotions sont provoquées par des éléments du réel[^panksepp] [^damasio] [^ekman] [^cabanac] [^emory] et peuvent être utiles, dans une certaine mesure, à une prise de décision plus efficace. [^pfister]

Seulement, les émotions conduisent souvent à des biais cognitifs et il faut donc s'en méfier lorssque nous voulons effectuer un raisonnement. Je cite encore Julia Galef à ce sujet[^galef_vulcan] :

> Comment les émotions nous rendent-elles irrationnelles ? Les émotions peuvent être épistémiquement irrationnelles si elles sont basées sur un faux modèle du monde. Les émotions peuvent être instrumentalement irrationnelles si elles vous empêchent d'atteindre vos objectifs.

Il faut aussi se rappeler que les émotions peuvent causer des *biais émotionnels* qui sont une déformation des connaissances ou des processus de décision.[^blanchette] [^trofimova] [^angie]

#### 5. Être rationnel signifie ne valoriser que des choses quantifiables, comme l'argent, l'efficacité ou la productivité

Au regard de la rationalité épistémique, *valoriser* quelque chose n'a pas de sens. Il s'agit de décrire le réel avec le plus de précision possible, pas de fiare des jugements de valeur.

Au regard de la rationalité instrumentale, tout dépend des objectifs qu'on s'est fixé. Si notre objectif est d'avoir une vie heureuse et pleine de découvertes artistiques, alors rechercher le bohneur et apprécier l'esthétique seront rationnels.

#### Synthèse

Je cite Julia Galef[^galef_vulcan] :

> Si vous pensez que vous agissez de manière rationnelle mais que vous continuez à obtenir la mauvaise réponse, et que vous finissez toujours plus mal que vous ne pourriez l'être, alors la conclusion que vous devriez en tirer n'est pas que la rationalité est mauvaise, c'est que vous êtes mauvais à la rationalité.
>
> En d'autres termes, vous vous trompez !

### Champs d'application

Comme le dit Richard Monvoisin[^monvoisin_these] :

> Il faut distinguer entre la croyance comme acte de foi (*faith*) et la croyance de type adhésion (*belief*).

Il est important de noter que la pensée critique s'applique et ne peut s'appliquer que dans ce qui relève de l'adhésion.

L'adhésion est donc, par opposition à la foi[^monvoisin_these] :

> Une croyance produite par une démarche d'énonciation de vérité susceptible d'être infléchie par le raisonnement ou l'expérience.

Par exemple, la croyance en Dieu relève de la foi (et se place donc hors du champ de la pensée critique) si elle n'est basée sur aucun élément tangible, et de l'adhéion dans le cas contraire. Si quelqu'un dit "je crois en Dieu par acte de foi", la pensée critique ne peut pas s'y appliquer, mais s'il dit "je crois en Dieu car sans Dieu il n'y aurait pas de morale" ou "je crois en Dieu car il faut bien que l'Univers ait une cause", la pensée critique peut s'y appliquer.

Voici quelques exemples d'énoncés relevant de la foi :

* Je n'aime pas Manuels Valls
* Dieu existe
* Le jazz c'est mieux que la musique classique

Et d'autres relevant de l'adhésion :

* Manger des yaourts fait grandir
* Le Suaire de Turin date du premier siècle
* Le Doliprane est efficace contre les maux de tête

### Pourquoi être rationnel ?

Richard Monvoisin résume la situation ainsi[^monvoisin_these] :

> La science n'est pas la seule manière d'investiguer le réel. Effectivement, tout un chacun a la possibilité de s'en remettre à l'introspection, à la lecture de Révélations, à l'art à la méditation ou à la gamme des mancies pour choisir et décider.
>
> La science, bien moins trépidante à première vue, a ceci d'intéressant qu'elle est construite pour être la « manière efficace » de décrire le réel. Tout y est fait pour éviter les biais subjectifs, et pour que les descriptions soient assorties de tous les bémols possibles, de l'écart type des résultats à la fiabilité, leur reproductibilité, etc.
>
> Il ne faut pas compter sur la science pour vous dire ce qui est « beau » dans une toile de Modigliani, ou pour apprécier la lecture des Chants de Maldoror. Par contre, si l'on veut savoir si quelque chose « marche », fonctionne, est efficace ou assure le plus de chances de réussite, la science est tout simplement faite pour ça.

Si donc notre objectif est d'atteindre nos objectifs au mieu, alors il est *utile* d'être rationnel au sens instrumental. Or pour celà nous nous basons sur un modèle de la réalité qui ne peut être rendus plus précis qu'en étant rationnel au sens épistémique.

La rationalité n'est pas un vertu ou un impératif moral, c'est une manière de penser qui nous permet de connaitre le réel avec plus de précision et de mieux réaliser nos objectifs.

Pour en savoir plus, visionnez l'excellente vidéo de Christophe Michel sur le sujet :

<iframe class="video-frame" src="https://www.youtube.com/embed/PFjX5tgu0iQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Intelligence et rationalité

Sans rentrer dans les détails, je vais éclaircir une confussion courrante entre intelligence et rationalité. Intelligence et rationalité sont très peu corrélées.[^stanovich]

Je reprend ici une métaphore proposée par Thomas Durand[^beauvoisine] :

> Être intelligent c'est avoir un gros moteur, être rationnel c'est avoir un bon frein, un bon volant.

Beaucoup de gens sont intelligents, peu sont rationnels. Et beaucoup de gens très intelligents croient des choses sans fondement, et dans leur domaine de compétence cela ne leur pose aucun problème.

En effet, beaucoup de champs spécialisés sont comme une piste de course en ligne droite. Ces gens, avec de très gros moteurs, peuvent franchir la ligne d'arrivée très vite. Qu'ils soient rationnels ou non n'a que peu d'importance puisqu'ils n'ont pas besoin de prendre de virages.

Seulement la vie n'est pas une piste droite, mais une route tortueuse avec de nombreux virages et embranchements. Être rationnel c'est être en mesure de négocier ces virages, de choisir les bons embranchements, etc.

C'est également pour cette raison qu'il faut se méfier des gens intelligents et non rationnels, car *quand ils se plantent, il se plantent plus fort*.[^beauvoisine]

<figure>
  <img src="{{ site.baseurl }}/assets/images/dragster.png" alt="Dragster" />
  <figcaption>Le dragster : intelligent mais pas rationnel. Rapide mais très peu maniable.</figcaption>
</figure>

<figure>
  <img src="{{ site.baseurl }}/assets/images/205.jpg" alt="Peugeot 205" />
  <figcaption>La 205 : pas intelligente mais rationnelle. Peu rapide mais maniable.</figcaption>
</figure>

<figure>
  <img src="{{ site.baseurl }}/assets/images/rally.jpg" alt="Voiture de rally" />
  <figcaption>La voiture de rally : intelligente et rationnelle. Rapide et maniable.</figcaption>
</figure>

### Attitude

Avant de nous plonger dans les méthodes de la pensée critique, je voudrais préciser quelques points sur l'attitude à avoir dans cette démarche :

* Nous avons peut-être un avis sur tout mais réellement un expertise sur très peu de chose. En l'absence de données suffisantes il est bon d'admettre notre ignorance et de suspendre notre jugement.
* Rien n'est vrai que jusqu'à preuve du contraire. Soyons prêts à faire évoluer nos convictions en cas d'émergence de nouveaux éléments probants.
* Le réel existe tel qu'il est, qu'il nous plaise ou non. Soyons honnêtes dans nos démarches épistémiques.
* La pensée critique et la démarche zététique ne sont pas prescriptives mais informatives. Nous restons parfaitement libres de nos choix, qu'ils soient rationnels ou non.
* Avant de se lancer dans un débat, il peut être utilse de demander à son interlocuteur s'il y a un élément qui pourrait le faire changer d'avis. Si la réponse est non alors il est dans un système de croyance par pure foi et un débat est probablement innutile. De même si la théorie qu'il défend a été construite avant de chercher les faits pour la soutenir, alors c'est mauvais signe et il est fort probable qu'il soit là aussi, au moins en partie, dans un système de croyance par pure foi.

## La faillibilité des sens et de l'esprit

"C'est vrai, je l'ai vu de mes propres yeux !" et "C'est vrai, je m'en rappelle très bien !" sont deux affirmations à prendre avec des pincettes quand on sait à quel point nos sens et notre mémoire peuvent être faillibles, même en fonctionnement "standard" (sans altération par un handicap, une maladie, une substance, etc.).

Dans cette section, je vais brièvement parler de la faillibilité de nos sens et de notre mémoire et donner quelques exemples.

### La faillibilité des sens

#### Les illusions visuelles

Les illusions visuelles sont des percéptions visuelles s'opposant à la réalité. Elles peuvent être :

* Physiques : la perception est faussée par un élément physique, par exemple une forte chaleur ou une faible humidité, qui dévie les rayons lumineux.
* Physiologiques : la perception est faussée par un effet du corps, comme pour les images rémanantes (quand la sensation visuelle persiste après la disparition du stimulus).
* Cognitives : la perception est faussée par une mauvaise interprétation de l'image.

##### Exemple d'illusion visuelle physiologique

Fixez l'oeil du Che Guevara dans l'image ci-dessous pendant une trentaine de secondes puis fermez les yeux. Vous voyes l'image persister (le noir étant devenu blanc et inversement).

<img class="picture" src="{{ site.baseurl }}/assets/images/Che_Guevara_afterimage.jpg" alt="Image rémanante du Che Guevara" />

##### Exemples d'illusions visuelles cognitives

Les voitures ci-dessous font la même taille :

<img class="picture" src="{{ site.baseurl }}/assets/images/cars.jpg" alt="Illusion taille des voitures" />

Regardez plutôt :

<img class="picture" src="{{ site.baseurl }}/assets/images/cars.gif" alt="Illusion taille des voitures (animé)" />

Les carrés A et B ont la même couleur :

<img class="picture" src="{{ site.baseurl }}/assets/images/greysquares.gif" alt="Illusion échiquier" />

Les droites sont parallèles :

<img class="picture" src="{{ site.baseurl }}/assets/images/zollner.jpg" alt="Illusion de Zollner" />

Dans cette vidéo, la danseuse peut tourner dans un sens ou dans l'autre selon le point sur lequel vous vous concentrez :

<iframe class="video-frame" src="https://www.youtube.com/embed/WAuLOVFDdp0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Pour voir quelques autres illusions, visionnez cette excellente publicité Honda de 2013 :

<iframe class="video-frame" src="https://www.youtube.com/embed/lZU8ojUBh0o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Il y a également un type particulier d'illusion visuelle, la paréidolie, qui consiste à identifier une forme familière à un stimulus informe ou sans rapport objectif, par exemple à reconnaitre une forme humaine ou animale dans le contour d'un nuage :

<img class="picture" src="{{ site.baseurl }}/assets/images/sad_tomato.jpg" alt="Tomate triste" />
<img class="picture" src="{{ site.baseurl }}/assets/images/birds.jpg" alt="Vol d'oiseaux" />
<img class="picture" src="{{ site.baseurl }}/assets/images/wall.jpg" alt="Mur" />

#### Les illusions auditives

Les illusions auditives sont des percéptions auditives s'opposant à la réalité. Ni les hallucinations auditives, qui ne se rapportent à aucun son, ni les acouphènes, qui sont un symptôme d'une défaillance du système auditif, ne sont des illusions auditives.

Dans cette vidéo, on entend "ba" ou "fa" selon l'image affichée alors que le son est le même (effet McGurk) :

<iframe class="video-frame" src="https://www.youtube.com/embed/G-lN8vWm3m0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Dans ce sketch, l'humoriste Serge Llado présente différentes chansons en langues étrangères en suggérant des paroles françaises faitaisistes au préalable. Il est alors difficile d'entendre autre chose. Il parle d'hallucination auditive mais le terme exact est *paréidolie auditive* :

<iframe class="video-frame" src="https://www.youtube.com/embed/b7aKj9XdsPg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Dans cet autre exemple, on entend soit *Yanny* soit *Laurel* en fonction de la fréquence perçue :

<iframe class="video-frame" src="https://www.youtube.com/embed/yDiXQl7grPQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

#### La surcharge cognitive

C'est quand notre cerveau a trop d'informations à gérer.

Regarder quelques images d'une campagne de publicité Colgate :

*Sur mobile, vous pouvez orienter votre appareil en paysage.*
{: .mobile-only}

<img class="picture" src="{{ site.baseurl }}/assets/images/colgate1.jpg" alt="Colgate 1" />
<img class="picture" src="{{ site.baseurl }}/assets/images/colgate2.jpg" alt="Colgate 2" />
<img class="picture" src="{{ site.baseurl }}/assets/images/colgate3.jpg" alt="Colgate 3" />

Vous avez remarqué les restes de nourriture coincés entre les dents des hommes ? Bien sûr ! On le remarque tout de suite. Mais avez vous remarqué que sur la première image il manque une oreille à l'homme, que sur la seconde la femme a un troisième bras et que sur la dernière elle a un sixième doigt ?

Un phénomène similaire est à jeu dans l'effet Stroop (interférences d'informations non pertinentes).

Essayez de dire la couleur des mots suivants :

<img class="picture" src="{{ site.baseurl }}/assets/images/stroop.png" alt="Effet Stroop" />

Enfin, regardez la vidéo suivante. Serez-vous être suffisamment attentifs ?

<iframe class="video-frame" src="https://www.youtube.com/embed/ubNF9QNEQLA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

#### Les illusions tactiles

Au même titre que les illusions visuelles et auditives, on trouve aussi des illusions tactiles. Par exemple :

* Le *lapin qui saute*[^geldard] [^bremer] [^flach], dans laquelle on tapote rapidement une personne à deux endroits différents (par exemple le coude et le poignet), et qui donne l'illusion d'être touché à plusieurs endroits entre ces deux zones.
* L'*effet Tau*[^helson] [^russo], lorsque des participants jugent la distance spatiale entre plusieurs tapotements distincts comme étant irrégulière alors que seul le rythme varie.
* En mangeant, si une personne tient un aliment avec une texture et une autre texture est présentée à la bouche, de nombreuses personnes perçoivent le croustillant de l'aliment comme étant entre les deux textures.[^barnett-cowan]
* En touchant certains objets à la forme visuellement trompeuse, on peut ressentir un trou à la place d'une bosse.[^robles-de-la-torre]

### La faillibilité de l'esprit

#### L'effet de cadrage

C'est présenter des informations d'une manière orientée sans en changer le sens exact (parler d'un "verre à moitié plein" plutôt qu'un "verre à moitié vide").

Dans une série d'expériences en 1981, Amos Tversky et Daniel Kahneman on posé une série de questions à plusieurs centaines de participants pour décrire cet effet[^tversky]. En voici un exemple :

**Version 1 :**

Vous avez 600 patients atteints d'une maladie mortelle.

* Avec un traitement A, 200 seront sauvés.
* Avec un traitement B, il y a 1 chance sur 3 de sauver les 600, et 2 chances sur 3 de n'en sauver aucun.

Quel traitement choisissez-vous ?

**Version 2 :**

Vous avez 600 patients atteints d'une maladie mortelle.

* Avec un traitement A, 400 mourront.
* Avec un traitement B, il y a 1 chance sur 3 qu'aucun ne meurt, et 2 chances sur 3 que les 600 meurent.

Quel traitement choisissez-vous ?

Les deux versions des questions donnent exactement les mêmes informations quant à l'efficacité et aux conséquences des deux traitements. Voici les résultats :

* Version 1 : 72% choisissent la première réponse.
* Version 2 : 78% choisissent la deuxième réponse.

D'autres questions du même type ou portant sur la manière de présenter les gains et les risques sont présentés dans leur article [The framing of decisions and the psychology of choice](https://www.uzh.ch/cmsssl/suz/dam/jcr:ffffffff-fad3-547b-ffff-ffffe54d58af/10.18_kahneman_tversky_{81}.pdf).

Une autre illustration de l'effet de cadrage se retrouve dans cet excellent exemple pédagogique :

<iframe class="video-frame" src="https://www.youtube.com/embed/iS-CJSlwpGM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

#### L'effet impact

C'est quand on utilise la connotation des mots pour induire une idée différente de ce que ces mots prétendent représenter.

En 2005 Richard Wiseman et Emma Greening on réalisé une expérience[^wiseman] impliquant 50 étudiants sur le campus de l'université de Hertfordshire au Royaume-Uni. Ils ont montré aux participants une vidéo d'un illusionniste tordant "par la pensée" une clé posée dans la paume de sa main, puis la posant sur une table devant lui. Le phénomène a été présenté comme étant paranormal.

Les étudiants devait répondre à la question "Une fois posée sur la table, la clé a-t-elle continué de se tordre ?" (la bone réponse étant "non").

Les étudiants étaient répartis aléatoirement en deux groupes isolés. Pour le second groupe, la vidéo contenait une séquence supplémentaire au début ou l'illusionniste suggérait que la clé continuerait de se tordre une fois posée.

Les résultats à la question pour les deux groupes sont :

|                            | Groupe 1 | Groupe 2 |
|----------------------------|----------|----------|
| La torsion continue        | 4 %      | 40 %     |
| La torsion ne continue pas | 96 %     | 60 %     |

L'expérience a été répétée, avec d'autres participants. Cette-fois la question demandait simplement de décrire le phénomène. Voici les resultats :

|                            | Groupe 1 | Groupe 2 |
|----------------------------|----------|----------|
| La torsion continue        | 0 %      | 36 %     |
| La torsion ne continue pas | 100 %    | 64 %     |

Celà illustre bien la puissance de cet effet. Il peut même avoir une influence si importante qu'on observe par exemples des effet physiologiques sur des patients en employant un mot plutôt qu'un autre lors du diagnostic.[^benedetti]

#### Les faux souvenirs

Chez tous les individus, même parfaitements saints, la mémoire est faillible, maléable.

La mémoire est consistituée de plusieurs registres[^baddeley] [^tulving] et stocke les informations de manière discontinue.[^montel] Il est par exemple difficile de réciter l'alphabet à l'envers en l'ayant appris uniquement à l'endrois.

Mais cela va bien plus loin.

Dans une expérience en 1979[^gentner], Dedre Gentner et Elizabeth Loftus ont présenté aux participants une série d'images accompagnées de légendes aux verbes génériques (par exemple "walk", marcher) pour le groupe 1 et spécifiques (par exemple "hike", randonner) pour le groupe 2.

Une semaine plus tard, ils leur ont montré une autre série d'images, contenant certaines des images de la première fois, de nouvelles images totalement différentes et certaines nouvelles mais dont le thème était le même que certaines de la première série. Ils leur ont demandé d'indiquer celles dont ils se souvenaient avec certitude.

36% ont indiqué se rappeler d'une image alors qu'elle ne leur avait pas été présentée mais dont le thème était le même. Cette proporsion atteignait 47% quand les images de la première semaine étaient accompagnées de légendes avec des verbes spécifiques.

D'autres expériences du même genre ont par exemple fait se "souvenir" à des étudiants la présence de certains objets lors d'un cours alors que seules des questions mentionnant ces objets y avaient été posées[^cole], intégré de faux éléments par suggestion dans le souvenir d'un accident[^loftus], fait accepter des affirmation contradictiores par l'introduction de faux souvenirs au moment opportun[^loftus_2], créé le faux souvenir d'une peur intense[^ramirez], etc.

D'autres études[^bjorklund] [^conway] [^roediger] [^schacter] [^loftus_3] [^roediger_2] [^roediger_3] [^loftus_4] [^payne] [^rubin] [^murphy] ont conduit de nombreuses expériences similaires et indiquent toutes que les souvenirs peuvent êtres modifiés, créés ou supprimés et que la mémoire n'est pas un témoin fiable.

## Les principes fondamentaux de la pensée critique

Voici quelques-uns des principes fondamentaux de la pensée critique. Ils servent de fondation à une réflexion plus poussée et priorisant les hypothèses les plus probables, en éliminants les arguments non pertinants d'un point de vue épistémique, etc.

Je les présente sommairement, sans détailler toutes leurs nuances et leur complexité, mais nous les verrons plus en détails dans des exemples concrets dans la suite de l'article.

### Le Rasoir d'Hitchens

**Ce qui peut être affirmé sans preuve peut être rejeté sans preuve.**

Si quelqu'un m'affirme "les licornes existent" sans apporter le moindre élément de preuve, je n'ai aucune raison de croire plus à leur existence qu'avant d'entendre ces propos.

Attention, il ne s'agit pas de pouvoir affirmer le contraire de l'affirmation. Si quelqu'un m'affirme "les licornes existent" sans apporter le moindre élément de preuve, le Rasoir d'Hitchens ne me permet pas d'affirmer "les licornes n'existent pas" sans preuve, bien que je puisse privilégier cette hypothèse (cf. [le principe de parcimonie des hypothèses](#le-principe-de-parcimonie-des-hypothèses-ou-rasoir-dockham)).

Le Rasoir d'Hitchens est fortement lié à l'*onus probandi*.

### L'*onus probandi*

**La charge de la preuve incombe à celui qui prétend.**

Comme l'expliquent Richard Monvoisin et Nicolas Pinsault[^monvoisin_pinsault] :

> C'est à celui qui prétend quelque chose de le prouver et non aux autres de prouver que ce qu'il prétend n'est pas vrai.
>
> Ce n'est pas aux critiques de Claude Vorilhon, alias Raël de prouver qu'il n'a pas pu être enlevé par des extraterrestres, mais bien à lui de démontrer qu'il l'a été. De la même façon, ce n'est pas aux critiques d'une technique de montrer qu'elle est inefficace, mais bien aux prétendants de montrer qu'elle possède l'efficacité que ceux-ci lui prêtent.
>
> Imaginons le bazar s'il fallait prendre pour vraie toute affirmation, par exemple sur un médicament, et devoir attendre que quelqu'un montre qu'elle est fausse pour y renoncer. Tout vendeur de potions pourrait rétorquer à vos doutes : "prouvez donc que ma potion n'est pas miraculeuse".
>
> Il est de toute façon logiquement impossible de montrer que quelque chose n'existe pas.

### Le principe de parcimonie des hypothèses (ou Rasoir d'Ockham)

**Les hypothèses suffisantes les plus parcimonieuses doivent être préférées.**

Il s'agit, entre plusieurs hypothèses au même pouvoir explicatif, de privilégier celle qui est la plus *parcimonieuse*, celle qui est la moins couteuse cognitivement, celle qui fait appel au moins d'autres hypothèses.

Cela implique que face à un phénoméne encore inexpliqué, on tentera d'abord de l'expliquer à partir de ce qui est connu avant de postuler l'extistence de quelque chose d'inconnu. Ou que face à trois symptomes simultanés on recherche d'abord une maladie pouvant causer ces trois symptômes plutôt que trois maladies causant chacune un symptôme.

Richard Monvoisin en donne un exemple[^monvoisin_these] :

> Je mets un chat et une souris dans une boîte, je ferme, je secoue, et j'ouvre : il ne reste plus que le chat.
>
> * Hypothèse 1 : des extraterrestres de la planète Mû ont voulu désintégrer la souris, mais elle s'est transformée en chat. Le chat, de frayeur, est passé dans une autre dimension par effet Tunnel.
> * Hypothèse 2 : le chat a mangé la souris.
>
> Vous m'accorderez que l'hypothèse 2 est beaucoup moins coûteuse intellectuellement que la N°1. Elle ne postule rien d'autre que la prédation de la souris par le chat, tandis que la première postule une planète Mû, des extraterrestres qui viennent, qui savent désintégrer un chat ce qui n'est pas donné à tout le monde, une souris qui se transforme en chat, une autre dimension, un chat qui sait y aller et un effet tunnel pour objet macroscopique. Ca fait beaucoup. Dans le doute, on choisira la 2.

Attention, il ne s'agit pas de dire que l'hypothèse parcimonieuse est vraie. En l'absence de preuve, nous ne pouvons êtres sûrs de rien. Il s'agit seulement de dire qu'il est plus *sage*, plus *rationnel* de privilégier celle-ci jusqu'à l'apparition éventuelle de nouveaux éléments probants.

### Le critère de réfutabilité

**Une proposition n'est recevable que si elle est réfutable.**

Une proposition est réfutable s'il existe un énoncé qui lui est contradictoire, c'est-à-dire qui la falsifierait s'il se révélait vrai. Par exemple la proposition "tous les cygnes sont blancs" est réfutable car il suffirait de trouver un cygne qui ne soit pas blanc pour l'infirmer.

Si une proposition n'est pas réfutable, alors elle n'a aucune valeur probante et n'est pas rationnelle.

## L'adhésion évolutive

Le concept d'*adhésion évolutive* est un élément extrêmement important de la pensée critique, qu'on utilise tous intuitivement, plus ou moins consciemment, avec plus ou moins de rigueur.

Afin de comprendre ce que c'est et comment l'utiliser, je vais d'abord parler d'*inférence bayésienne*, le mécanisme probabiliste sur lequel repose l'*adhésion évolutive*, puis de *curseurs de croyance* qui sont un représentation mentale de ce mécanisme, bien plus simple et plus pratique dans la vie de tous les jours.

### L'inférence bayésienne

Tout d'abord, qu'est-ce qu'une inférence ?

C'est[^tlfi_inference] :

> Une opération logique par laquelle on admet une proposition en vertu de sa liaison avec d'autres propositions déjà tenues pour vraies.

Il existe deux approches, celle plus simple et courrante, *fréquentiste*, et celle un peu plus complexe et moins courrante, *bayésienne*.

* L'*inférence fréquentiste* c'est déterminer la probabilité des faits en fonction des hypothèses.
* L'*inférence bayésienne* c'est déterminer la probabilité des hypothèses en fonction des faits.

En gros, l'*inférence fréquentiste* détermine $$P(x \vert H)$$ la **vraissemblance** des résultats x dans le carde de l'hypothèse H, et l'*inférence bayésienne* détermine $$P(H \vert x)$$ la **plausibilité** de l'hypothèse H au vu des résultats x.

Note : $$P(A \vert B) $$ se lit *probabilité de A sachant B*.

Illustrons les deux méthodes par un exemple.

Imaginons que j'ai plusieurs dés avec un nombre de faces différents (par ex. 4, 6, 8, 10, 12 et 20).

<img class="picture medium" src="{{ site.baseurl }}/assets/images/dice.png" alt="Dés" />

Je prends un dé à 8 faces, je le lance 3 fois à j'obtiens 7 à chaque fois. Est-ce extraordinaire ?

Avant de pouvoir répondre à cette question, nous devont nous mettre d'accord sur ce qui constitue une série de lancers extraordinaire. Disons que c'est toute série qu'on a moins de 1% de chances d'obtenir par hasard. Notez que j'ai choisi 1% de manière arbitraire et qu'on aurait très bien pu choisir 2% ou 0,1%.

Notons $$D_n$$ l'utilisation d'un dé à *n* faces (par exemple $$D_8$$ pour un dé à 8 faces), et $$R_x$$ l'obtention du résultat *x* (par exemple $$R_7$$ pour un 7).

La probabilité d'obtenir trois fois 7 avec trois lancers d'un dé à 8 faces est :

$$
P(R_{7,7,7} \vert D_8) = \dfrac{1}{8 \cdot 8 \cdot 8} \approx 0.2 \%
$$

Il s'agit donc d'un résultat extraordinaire. Remarquez que si on avez choisi un seuil de 0,1%, le résultat serait ordinaire. La conclusion dépend donc bien des critères choisis au départ, d'où l'importance de s'accorder sur les critères avant tout débat ou expérience.

Nous venons d'effectuer un raisonnement d'*inférence fréquentiste* : nous avons déterminé la probabilité des faits (une série de trois 7) en fonction des hypothèses (trois lancers d'un dé à 8 faces).

Là ou l'*inférence bayésienne* entre en jeu et devient extrêmement intéressante c'est quand on se pose un autre type de question.

Imaginons que je prends un des dés sans que vous sachiez lequel. Je le lance en cachette et j'annonce le résultat : 7. Quelle dé ai-je le plus probablement utilisé ?

Avec l'*inférence fréquentiste* on pourrait seulement dire que parmis les dés qui ont au moins 7 faces (8, 10, 12 et 20), tous ont une chance d'avoir été choisis, donc 25% de chance pour chaque. Mais celà est faux ! Car le résultat du dé nous donne une information supplémentaire, qu'on peut exploiter avec l'*inférence bayésienne*.

L'inférence bayésienne est basée sur le *Théorème de Bayes* :

$$
P(A|B) = \dfrac{P(B|A) \cdot P(A)}{P(B)}
$$

Il se lit : *la probabilité de A sachant B est égale à la probabilité de B sachant A multipliée par le probabilité de A divisée par la probabilité de B*.

On peut le réécrire en remplaçant A par H (hypothèse) et B par x (fait). On a alors :

$$
P(H|x) = \dfrac{P(x|H) \cdot P(H)}{P(x)}
$$

Où :

* $$P(H \vert x)$$ est la **plausibilité** de l'hypothèse H au vu des résultats x
* $$P(x \vert H)$$ est la **vraissemblance** des résultats x dans le carde de l'hypothèse H
* $$P(H)$$ est la **plausibilité à priori** de l'hypothèse H
* $$P(x)$$ est la **probabilité toutes hypothèses confondues** des résultats x

Dans notre cas, ce qui nous intéresse c'est la probabilité d'avoir utilisé un dé sachant le résultat obtenu.

Dans notre exemple, on sait que le résultat est 7. On cherche donc pour chaque dé :

$$
P(D_n|R_7) = \dfrac{P(R_7|D_n) \cdot P(D_n)}{P(R_7)}
$$

Où :

* $$P(D_n \vert R_7)$$ est la probabilité d'avoir utilisé un dé à *n* faces sachant qu'on a fait un 7
* $$P(R_7 \vert D_n)$$ est la probabilité de faire un 7 avec un dé à _n_ faces
* $$P(D_n)$$ est la probabilité d'avoir un dé à n faces
* $$P(R_7)$$ est la probabilité de faire un 7 peu importe le dé

On sait que les dés à 4 et 6 faces ne peuvent donner de 7, il nous reste donc ceux à 8, 10, 12, et 20 faces.

Il reste donc à calculer $$P(D_8 \vert R_7)$$, $$P(D_{10} \vert R_7)$$, $$P(D_{12} \vert R_7)$$ et $$P(D_{20} \vert R_7)$$.

Supposons, à priori, que chaque dé a une chance égale d'être choisi (c'est là la part subjective qui doit être introduite lors de l'étape initiale et qui s'atténue au fil des expériences). On a donc :

$$P(D_8) = P(D_{10}) = P(D_{12}) = P(D_{20}) = 25\%$$

Calculons ensuite la probabilité de faire un 7 quelque soit le dé. Elle vaut la probabilité de faire un 7 avec un dé à 8 faces fois la probabilité d'avoir un dé à 8 faces, plus la probabilité de faire un 7 avec un dé à 10 faces fois la probabilité d'avoir un dé à 10 faces, etc.

$$P(R_7) =  \dfrac{1}{8} * 0.25 + \dfrac{1}{10} * 0.25 + \dfrac{1}{12} * 0.25 + \dfrac{1}{20} * 0.25 \approx 8.96\%$$

On dispose maintenant de toutes les informations pour calculer les différentes $$P(D_n \vert R_7)$$.

$$P(D_8 \vert R_7) = \dfrac{1/8 \cdot 0.25}{0.0896} \approx 34.9\%$$

$$P(D_{10} \vert R_7) = \dfrac{1/10 \cdot 0.25}{0.0896} \approx 27.9\%$$

$$P(D_{12} \vert R_7) = \dfrac{1/12 \cdot 0.25}{0.0896} \approx 23.3\%$$

$$P(D_{20} \vert R_7) = \dfrac{1/20 \cdot 0.25}{0.0896} \approx 13.9\%$$

Le dé a 8 faces est donc le plus probablement (34,9%) celui utilisé. Pour s'en assurer il serait cependant fort utile de répliquer l'expérience.

Faisons un autre lancer avec le même dé caché (sans toujours savoir réellement duquel il s'agit).

Le résultat est 3.

Nous pouvons alors recalculer nos probabilité. La grande différence est que cette fois-ci nous avons déjà un indice sur les probabilités à priori : alors que nous avions avant choisi 25% pour chaque dé  (ce qui est sensé mais, en l'absence de preuve, reste arbitraire), nous pouvons maintenant utiliser les résultats précédents comme valeurs à priori (les fameux $$P(D_n)$$).

Calculons d'abord la nouvelle valeur de $$P(R_7)$$ :

$$P(R_7) = \dfrac{1}{8} * 0.349 + \dfrac{1}{10} * 0.279 + \dfrac{1}{12} * 0.233 + \dfrac{1}{20} * 0.139 \approx 9.79\%$$

Calculons alors de nouveau les différents $$P(D_n \vert R_7)$$ :

$$P(D_8 \vert R_7) = \dfrac{1/8 \cdot 0.349}{0.0979} \approx 44.6\%$$

$$P(D_{10} \vert R_7) = \dfrac{1/10 \cdot 0.279}{0.0979} \approx 28.5\%$$

$$P(D_{12} \vert R_7) = \dfrac{1/12 \cdot 0.233}{0.0979} \approx 19.8\%$$

$$P(D_{20} \vert R_7) = \dfrac{1/20 \cdot 0.139}{0.0979} \approx 7.1\%$$

Notre exemple avec les dés est une métaphore de la méthode scientifique. Le résultat du dé est le résultat d'une expérience, et les différents dés sont les différentes hypothèses pouvant expliquer le résultat.

Si on se limitait à une approche fréquentiste, il se pourrait que plusieurs hypothèses nous semblent équivalentes et on ne pourrait pas trancher. Mais avec une approche bayésienne, plus complexe mais plus puissante, ont dispose d'un outil pour discriminer les hypothèses selon leur probabilité au regard des résultats.

Il est intéressant de noter que chacun de nos lancers a conforté l'hypothèse du dé à 10 faces, mais qu'ils ont conforté encore plus celle du dé à 8 faces. Cela montre l'importance de ne pas privilégier une hypothèse isolée juste parce que les faits la confirment, encore faut-il qu'elle soit celle qui le soit le plus.

En effet, imaginons que j'adopte une approche simpliste de la science et que je défende l'hypothèse "c'est le dé à 10 faces qui est utilisé". Je fais deux lancers (deux expériences) et chacun confirme mon hypothèse. Je clamme alors haut et fort "j'avais raison, c'est le dé à 10 faces, c'est prouvé !".

Une approche méthodique, par l'inférence bayésienne, donne un résultat plus précis en hiérarchisant les hypothèses en fonction de leur plausibilité au regard des faits.

Pour conclure cette partie, voici une petite illustration :

<figure>
  <img src="{{ site.baseurl }}/assets/images/conditional_risk.png" alt="XKCD 795" />
  <figcaption>
  — Whoa ! On devrait rentrer !
  <br/>
  — C'est bon ! Les éclairs ne tuent que 45 américains par an, les chances de mourrir sont de seulement une sur 7000000. Continuons !
  </figcaption>
</figure>

Cette image illustre la différence qu'il y a entre $$P(H)$$ et $$P(H \vert x)$$ :

* $$P(H)$$ : la probabilité de mourrir de la foudre
* $$P(H \vert x)$$ : la probabilité de mourrir de la foudre en étant près d'un arbre durant un orage

### Les curseurs de croyance

Dans la vie courrante, nous n'allons pas calculer des probabilités bayésiennes à chaque fois qu'un problème se pose. Il nous serait donc fort utile de bénéficier des avantages de ce mécanisme en se débarassant d'une partie de sa complexité.

C'est là qu'entrent en jeu les *curseurs de croyance*, ou *curseurs de plausibilité*, qui permettent de se représenter bien plus facilement et intuitivement ces mécanismes.

Il s'agit d'associer à chacune de nos croyances un curseur allant de 0 à 100 %, de "je n'y crois absolument pas" à "j'y crois absolument", de "je n'ai que des doutes, aucune certitude" à "je n'ai que des certitudes, aucun doute". Ce curseur peut ensuite évoluer dans un sens ou un autre en fonction des nouveaux éléments dont nous avons connaissance, et plus ou moins loin en fonction de la solidité des preuves.

Pour chaque hypothèse, j'ajuste mon curseur en fonction de mon adhésion. Et à chaque fois que j'ai connaissance d'un nouvel élément probant, je déplace mon curseur.

Julia Galef illustre ce processus sous forme de diagramme[^galef_diag] :

<img class="picture" src="{{ site.baseurl }}/assets/images/curseurs.png" alt="Curseurs de croyance" />

Dans la colonne de gauche, on trouve nos hypothèses, telle qu'on y adhère à un instant *t*. Par exemple je crois à l'hypothèse H1 à 40% et à l'hypothèse H2 à 60%.

Le carré central représente les nouveaux éléments probants qui arrivent à notre connaissance. Les deux zones V1 et V2 représentent la *vraissemblance* des résultats au vu des hypothèses H1 et H2. Plus la zone est large, plus la vraissemblance est forte.

Dans la colonne de droite, on retrouve nos hypothèses, ajustées en fonction des vraissemblances. On augmente notre adhésion en fonction de la surface des rectangles de la zone centrale.

Pour que ça soit plus clair, prenons un exemple concret, en nous aidant de l'excellent outil visuel créé par Christophe Michel.

Il peut être utilisé en ligne (<https://www.geogebra.org/m/Y3epyFff>) ou ouvert sur l'application GeoGebra sur ordinateur ou smartphone.

Il permet une interraction avec le diagramme et de jouer avec les probabilités :

<img class="picture" src="{{ site.baseurl }}/assets/images/bayes_gg_00.png" alt="Bayes N&B" />

Pour notre exemple, imaginons que je me demandent qui a construit les pyramides d'Égypte et que j'ai trois hypothèses :

* H0 : les Égyptiens antiques ont construit les pyramides. J'y crois à 19,38 %.
* H1 : les extraterrestres ont construit les pyramides. J'y crois à 32,56%.
* H2 : les pyramides ont été construites par les romains (et ont donc environ 2000 ans). J'y crois à 48,06%.

Or j'apprends qu'on a daté les pyramides à plus de 4000 ans et le test me semble fiable. Les résultats de l'expérience sont vraissemblables de la même manière dans le cas des hypothèses H0 et H1 et ne le sont pas pour H2. J'adapte mes curseurs en conséquence :

<img class="picture" src="{{ site.baseurl }}/assets/images/bayes_gg_01.png" alt="Bayes N&B" />

Je crois maintenant en H0 à 35,58%, en H1 à 59,78% et en H2 à 4,64%.

Un nouvel élément de preuve apparait : les bâtisseurs utilisaient des outils antiques et on a pû démontrer leur efficacité pour découper le granit. Cet faits sont vraiseemblables pour H0 et H2 et non pour H1 (les extraterrestres ont une technologie avancée). J'adapte mes curseurs en conséquence :

<img class="picture" src="{{ site.baseurl }}/assets/images/bayes_gg_02.png" alt="Bayes N&B" />

Je crois maintenant en H0 à 82,06%, en H1 à 7,25% et en H2 à 10,69%.

Et, jusqu'à l'apparition de nouveaux éléments probants, ce sera ma croyance.

*Note : dans le cas où les probabilités de plusieurs hypothèses sont très proches, il est sage de ne pas choisir une hypothèse, même si elle est la plus probable, et d'attendre d'autres éléments de preuve.*

<!-- TODO -->
<div class="wip-warning">
    <p>🚧</p>
    <p class="bold">À faire</p>
    <p>Même exemple avec une personne qui a des valeurs différentes au départ et aboutit à une conclusion  différente.</p>
</div>

## Les niveaux de preuve

Retrouvez un résumé de cette section ici : [[En bref] Les niveaux de preuve]({{ site.baseurl }}/bref/niveaux-preuve)
{: .read-short-info}

Une preuve est, d'une manière très générale[^antidote_preuve] :

> Ce qui sert à établir qu'un fait est vrai.

Plus spécifiquement, une preuve scientifique est une preuve qui sert à supporter ou réfuter une hypothèse ou théorie scientifique, c'est à dire qui respecte le critère de scientificité (toute affirmation objectivable découlant d'une démarche intellectuelle structurée).

Or il n'est pas difficile de concevoir que toutes les preuves ne se valent pas.

Dans le cadre d'une démarche rationnelle, on peut hiérarchiser les preuves selon des niveaux de fiabilité.[^afis_preuve] [^grades_burns] [^grades_bjm] [^grades_hadorn] [^grades_petrisor] [^grades_wilson] [^grades_has]

* Niveau de preuve très élevé (Grade A – Preuve établie)
  * Consensus scientifique
  * Méta-analyses

* Niveau de preuve élevé (Grade B – Présomption)
  * Essais comparatifs randomisés
  * Études de cohortes

* Niveau de preuve modéré (Grade C+ – Preuve modérée)
  * Études prospectives contrôlées
  * Études cas-témoin

* Niveau de preuve faible (Grade C- – Preuve faible)
  * Étude de cas
  * Études rétrospectives
  * Études prospectives non contrôlées
  * Études épidémiologiques descriptives

On peut aussi hiérarchiser les *indices*, qui n'ont **aucune valeur probante** :

* Indices forts
  * Parole d'expert

* Indices moyens
  * Expérience personnelle
  * Témoignage individuel direct

* Indices faibles
  * Témoignage individuel indirect
  * Sagesse populaire

*Note : des études dont la méthodologie est mauvaise (manque de contrôle, biais statistiques ou d'échantillonage, etc.) et qui sont de fait rejetées par la communauté scientifique peuvent parfois avoir une valeur d'indice.*

Ainsi, lorque nous mettons à jour nos curseurs de croyance, il nous faut prendre en compte le niveau de fiabilité des preuves apportées.

Imaginons par exemple que je me docummente sur l'efficacité de la sève d'artémisia sur les brûlures du premier degré. A un instant *t* je dispose de deux preuves : un essai comparatif randomisé indiquant son efficacité et une étude cas-témoin indiquant son inneficacité. Dans ce cas, placer mon curseur à 50% serait fautif, ce serait considérer que les deux études ont la même valeur probante. Je vais plutôt le placer à 80% en faveur de l'efficacité. En effet l'essai comparatif randomisé est une preuve de grade B, donc plus probante que l'étude cas-témoin de grade C+.

Les niveaux de preuve ne sont pas les seuls critères à prendre en compte. Bien sûr on peut exclure les études qui ont des biais méthodologiques, d'échantillonage, d'évaluation, etc., mais il faut également considérer la taille des échantillons, les traitements statistiques des données, etc.

Je ne rentre pas dans les détails et ferai peut-être un article dédié pour expliquer tout cela.

## Quelques outils méthodologiques

Dans cette section je décrit brièvement quelques outils méthodologiques de base pour mener à bien une réflexion critique.

### Partir des faits

Toute explication non etayée par des faits *qui la démontrent* n'est pas une preuve, aussi cohérente soit-elle. Ce qui nous intéresse ce n'est pas à quel point une hypothèse explique les faits, mais à quel point les faits confirment l'hypothèse et si celle-ci est la plus plausible parmi toutes les hypothèses au vu des faits.

Il est donc important d'aller des faits vers les hypothèses et non l'inverse. Cela ne signifie pas que nous ne pouvons postuler aucune hypothèse sans avoir d'abord examiné les faits. Bien souvent d'ailleurs on nous présente plusieurs hypothèses avant que nous ayons eu l'occasion de nous renseigner sur les faits.

Il s'agit de ne pas favoriser une hypothèse à priori, et de ne pas chercher les faits qui valident une hypothèse mais bien d'évaluer les hypothèses au regard des faits.

<img class="picture" src="{{ site.baseurl }}/assets/images/methode.jpg" alt="Méthode scientifique" />

### Assurons-nous bien du fait, avant de nous inquiéter de la cause

Bernard Le Bouyer de Fontenelle, écrivain et scientifique français, écrivait en 1687[^fontenelle] :

> Il serait difficile de rendre raison des histoires et des oracles que nous avons rapportés, sans avoir recours aux démons, mais aussi tout cela est-il bien vrai ? Assurons-nous bien du fait, avant de nous inquiéter de la cause. Il est vrai que cette méthode est bien lente pour la plupart des gens, qui courent naturellement à la cause, et passent par-dessus la vérité du fait ; mais enfin nous éviterons le ridicule d'avoir trouvé la cause de ce qui n'est point.
>
> Rien n'est plus normal que d'en faire autant sur toutes sortes de matières. Je ne suis pas si convaincu de notre ignorance par les choses qui sont, et dont la raison nous est inconnue, que par celles qui ne sont point, et dont nous trouvons la raison. Cela veut dire que non seulement nous n'avons pas les principes qui mènent au vrai, mais que nous en avons d'autres qui s'accommodent très bien avec le faux.

Cette maxime, *assurons-nous bien du fait, avant de nous inquiéter de la cause*, est l'un des piliers de la pensée critique.

Pour en savoir plus :

<iframe class="video-frame" src="https://www.youtube.com/embed/IduaHsRywuw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Logique de base

#### Implication, contraposée, réciproque, équivalence

En logique cest trois termes sont centraux.

L'implication exprime une relation de causalité selon laquelle une proposition en entraine une autre si elle est vraie. Elle se note $$A \Rightarrow B$$ et se lit *A implique B*.

La contraposée d'une implication est sa réécriture sous une forme négative. Elle a exactement la même valeur logique. La contraposée de $$A \Rightarrow B$$ (A implique B) est $$\neg B \Rightarrow \neg A$$ (non B implique non A).

La réciproque d'une implication est son inverse. Elle n'a pas la même valeur logique. La réciproque de $$A \Rightarrow B$$ (A implique B) est $$B \Rightarrow A$$ (B implique A).

On parle d'équivalence quand une implication et sa réciproque sont toutes les deux vraies. Elle se note $$A \Leftrightarrow B$$ et se lit *A équivaut à B*. On dit aussi que *A est nécessaire et suffisant à B*.

#### Modus Ponens et Modus Tollens

Derrière ces termes latins se cachent deux principes très simples et fondamentaux de la logique.

Le *modus ponens* est la *déduction du conséquent*. C'est à dire que si *A implique B* et que *A est vrai*, alors *B est vrai*. On écrit formellement cette relation :

$$A, A \Rightarrow B \vdash B$$

Cela se lit *de A et A implique B on déduit B*.

Par exemple :

1. On sait que tous les poissons respirent sous l'eau. ($$A \Rightarrow B$$)
2. Or le saumon est un poisson. ($$A$$)
3. Donc le saumon respire sous l'eau. ($$B$$)

Le *modus tollens* est la *validité de la contraposée*. La contraposée de *A implique B* est *non A implique non B*. On écrit formellement cette relation :

$$A \Rightarrow B \vdash \neg B \Rightarrow \neg A$$

Cela se lit *de A implique B on déduit non B implique non A*.

Par exemple :

1. On sait que tous les poissons respirent sous l'eau. ($$A \Rightarrow B$$)
2. Or l'ours ne respire pas sous l'eau. ($$\neg B$$)
3. Donc l'ours n'est pas un poisson. ($$\neg A$$)

#### Affirmation du conséquent et négation de l'antécédent

Les deux principes précédents sont logiquement valides, mais il existes deux raisonnement fallacieux très similaires dans leur forme qui sont logiquement invalides : l'*affirmation du conséquent* et la *négation de l'antécédent*.

L'*affirmation du conséquent* c'est considérer une condition suffisante comme nécessaire. Elle dit que si *A implique B* et que *B est vrai*, alors *A est vrai*. On écrit formellement cette affirmation fausse :

$$B, A \Rightarrow B \vdash A$$

Cela se lit *de B et A implique B on déduit A*.

Par exemple :

1. On sait que tous les poissons respirent sous l'eau. ($$A \Rightarrow B$$)
2. Or le crabe respire sous l'eau. ($$B$$)
3. Donc le crabe est un poisson. ($$A$$)

La *négation de l'antécédent* c'est considérer que la réciproque d'une implication est toujours vraie. Elle dit que si *A implique B* alors *non A implique non B*. On écrit formellement cette affirmation fausse :

$$A \Rightarrow B \vdash \neg A \Rightarrow \neg B$$

Cela se lit *de A implique B on déduit non A implique non B*.

Par exemple :

1. On sait que tous les poissons respirent sous l'eau. ($$A \Rightarrow B$$)
2. Or le crabe n'est pas un poisson. ($$\neg A$$)
3. Donc le crabe ne respire pas sous l'eau. ($$\neg B$$)

### Bien définir l'hypothèse testée

Lorsqu'on veut s'assurer de la véracité d'une hypothèse, il est très important de bien la définire avant d'investiguer. On ne teste qu'un seul paramètre à la fois, tous les autres paramètres étant égaux par ailleurs.

Prenons un exemple.

Lors d'un voyage en Armorique je croise le druide Panoramix, qui m'explique que la potion magique ne fonctionne que si on ajoute du gui cueilli à minuit, en toge blanche, pieds nus, dans un chêne avec une serpe d'or.

<img class="picture medium" src="{{ site.baseurl }}/assets/images/panoramix.jpg" alt="Panoramix" />

Ah ? Je décide de tester. Je ceuille du gui à 20h, en jeans, avec des chaussures, dans un tilleul avec un serpe en argent. Et, effectivement, la potion ne marche pas. Je teste ensuite en faisant comme Panoramix a dit et là, ça marche.

Ai-je bien testé son affirmation ? Non. En effet, j'ai fait varier tous les paramètres en même temps. Dans ce cas, comment savoir s'ils ont tous un effet.

J'aurais par exemple pu tester l'influence de l'heure de ceuillette en ajoutant du gui cueilli à 20h, en toge blanche, pieds nus, dans un chêne avec une serpe d'or. Si dans ce cas cela ne marche pas (en supposant qu'on a répliqué l'expérience de nombreuses fois, etc.) alors c'est bien que l'horaire a une influence. Si ça marche quand même, c'est qu'il n'a pas d'influence.

### Avoir des paramètres clairs, objectivables, quantifiables

Afin de pouvoir éprouver des hypothèses, il faut définir des paramètres qui ne soient pas ambigus.

Par exemple, si on charche à éprouver l'affirmation selon laquelle diffuser de la musique favorise la croissance des plantes, il faut par exemple préciser :

* Parle-t-on de toute musique classique ou seulement une sous-catégorie ?
* Quelle type de diffusion ? (durée, fréquence, volume, etc.)
* Est-ce que ça marche sur toutes les plantes ?
* Combien de temps doit-on attendre avant d'avoir un effet ?
* Qu'est-ce qu'on mesure ? (taille des plantes, nombre de graines, la masse sèche, etc.)
* Quels seuils significatifs ? Si on a choisi de mesurer l'effet sur la taille, quelle augmentation faut-il atteindre et en combien de temps pour que ça soit significatif ?
* Etc.

### Comparer à un échantillon standard

Lors de toute thérapie, des effets contextuels influent sur les symptômes et la rémission des patients.[^blasi] Le plus connu de ces effets est *l'effet placébo*, qui est un procédé thérapeutique n'ayant pas d'efficacité propre mais agissant sur le patient par des mécanismes psychologique et physiologiques.

Si on teste une thérapie, par exemple un nouveau médicament, il nous faut déterminer s'il a une efficacité propre, c'est-à-dire s'il est plus efficace que la guérison spontanée du corps combinée aux effets contextuels.

Par exemple si je veux tester l'efficacité du jus de citron sur les maux de tête, il n'est pas suffisant de l'administrer à des personnes souffrant de maux de têtes et de regarder si une heure après elles vont mieux. En effet, peut-être ont-elles guéri par effet placébo, ou même simplement parce que le mal de tête s'est naturellement résorbé.

Le protocole standard vise à comparer deux groupes, un (le *groupe test*) auquel on administre le médicament évalué et l'autre (le *groupe contrôle*) auquel on donne un placébo en tout point identique (même couleur, forme, odeur, goût, etc.) mais auquel on a retiré le principe actif que l'on veut tester. On compare ensuite les effets dans les deux groupes.

Ce protocole est d'une extrême importance car les effets contextuels ont une grosse influence sur l'état des patients, notamment sur les douleurs, nausées et fatigues.[^blasi]

Les effets contextuels et les protocoles de tests cliniques feront peut-être l'objet d'un article ultérieur, bien plus détaillé, car le sujet est vaste.

Ce qu'il faut bien retenir, c'est qu'il faut toujours s'assurer de comparer nos résultats avec un groupe contrôle, même lorsqu'il ne s'agit pas de tests médicaux.

Par exemple si on cherche à mettre à l'épreuve les prétentions d'un sourcier, il faut comparer ses capacités à trouver de l'eau à celles de personnes aussi familières que lui avec la région qu'il arpente mais qui n'ont pas de "don" de sourcier. En effet, s'il trouve de l'eau plus souvent que le commun des mortels, peut-être est-ce parce qu'il connait bien la fôret et sait quelles plantes poussent près des points d'eau ?

Dans cet exemple, idéalement on devrait monter un protocole indépendant de l'environnement. Par exemple on pourrait prendre un terrain complètement uniforme sous lequel on fait passer un large tuyau dans lequel on peut envoyer de l'eau à volonté. On demande au sourcier de se placer dessus et de déterminer si oui ou non de l'eau coule sous ses pieds.

D'ailleurs, de nombreux protocoles de ce genre ont été mis en place pour tester des centaines de sourcier. Aucun sourcier n'a pû faire montre d'une efficacité supérieure au hasard.[^marks] [^hines] [^regal] [^vogt]

Richard Monvoisin illustre la nécessité d'un groupe contrôle par l'histoire du panneau anti-girafe[^hauteurs] :

> Deux types sont dans le désert. Il y en a un qui est en train de planter un panneau.
>
> L'autre lui demande :
>
> — Mais tu fais quoi ?
>
> — Je plante un panneau anti-girafe !
>
> — Mais il n'y a pas de girafes dans le désert !
>
> — Ah ! C'est bien la preuve que ça marche !

<img class="picture medium" src="{{ site.baseurl }}/assets/images/anti-girafe.png" alt="Panneau anti-girafe" />

### Partir de l'hypothèse nulle

Ce point méthodologique découle du *principe de parcimonie des hypothèses* vu plus tôt. Il dit qu'en l'absence de preuve du contraire, il n'y a aucune raison de privilégier un échantillon ou un groupe plutôt qu'un autre.

On appelle *hypothèse nulle* cette hypothèse de départ qui postule l'égalité des paramètres statistiques. Par exemple l'hypothèse nulle dans un test clinique postule qu'il n'y a pas de différence d'effet entre un groupe qui prend un médicament et un autre qui prend un placébo. Le but de l'essai clinique est alors de vérifier si cette hypothèse se confirme ou si le médicament a bien un effet propre.

### Faire un échantillonage sans biais

Lorsqu'on choisit un échantillon (notamment de population) pour effectuer des tests, il doit être justifié et représentatif de ce qu'on veut tester. Par exemple si on veut évaluer le taux de confiance des Français en la médecine, on aura des résultats très différents selon qu'on fait notre sondage à la sortie du bar du coin ou de la faculté de médecine.

Les méthodes d'échantillonages peuvent êtres très complexes et varier grandement en fonction du type de problème. Voici cependant deux conseils, très basiques, pour avoir une première approche pas trop mauvaise.

Tout d'abord l'échantillon doit éviter les biais de sélection, c'est à dire qu'il ne doit pas contenir de sous-groupe déséquilibré pouvant infléchir les résultats. Par exemple si je teste l'efficacité d'un médicament pour les maux de tête, je ne dois pas avoir plus de gens qui ont des migraines chroniques dans le groupe contrôle que dans le groupe test.

Ensuite l'échantillon doit être suffisament grand pour que le test soit à la fois puissant (être en mesure de rejeter l'hypothèse nulle avec une grande probabilité si celle-ci est fausse) et significatif (être en mesure de conserver l'hypothèse nulle avec une grande probabilité si celle-ci est vraie).

D'une manière générale, on peut avoir une idée grossière de la taille minimale que devrait avoir un échantillon pour éviter les biais statistiques (en supposant qu'il soit par ailleurs représentatif) avec la formule suivante :

$$N = \frac{t^2 \cdot p \cdot (1-p)}{m^2}$$

Avec :

* $$N$$ la taille minimale de l'échantillon
* $$t$$ le niveau de confiance selon *la loi normale centrée réduite* (par ex. 1.96 pour 95% de confiance)
* $$p$$ la proportion estimée de la population qui présente la caractéristique (lorsque inconnue, on utilise $$p = 0.5$$, c'est-à-dire la [dispersion statistique](https://en.wikipedia.org/wiki/Statistical_dispersion) la plus grande)
* $$m$$ la marge d'erreur tolérée

Note 1 : le niveau de confiance indique le pourcentage de résultats qui sont propablement vrais (plus ou moins la marge d'erreur). Par exemple si on a un niveau de confiance de 90% et une marge d'erreur de 5%, alors on peut dire que 90% de nos résultats sont vrais à 5% près.

Note 2 : on peut calculer facilement la valeur de $$t$$ dans Excel en utilisant la formule *LOI.NORMALE.STANDARD.INVERSE.N*.

Par exemple, imaginons que nous volons tester si les êtres humains sont sensibles aux ondes 5G, avec 95% de confiance et 1% de marge d'erreur. On a :

$$N = \frac{1.96^2 \cdot 0.5 \cdot (1-0.5)}{0.01^2} = 9604$$

Notre étude devrait donc porter sur au moins 9604 personnes pour éviter les biais statistiques.

On peut se servir de la même formule pour évaluer, grossièrement, la confiance que l'on peut accorder à un test statistique en fonction de la taille de l'échantillon. En effet, on peut l'écrire ainsi :

$$t = \sqrt{ \frac{N \cdot m^2}{p \cdot (1-p)} }$$

Par exempel sin on avait conduit notre étude précédente sur un échantillon de 1000 personnes, on aurait :

$$t = \sqrt{ \frac{1000 \cdot 0.01^2}{0.5 \cdot (1-0.5)} } \approx 0.63$$

Ce qui correspond (via la formule *LOI.NORMALE.STANDARD.N* sous Excel) à une confiance à 74%, c'est à dire que 74% des résultats sont dans la marge d'erreur acceptable.

Ces symboles mathématiques peuvent parraitre compliqués mais ler utilisation est en réalité très simple. Leur utilisation n'est pas très courrante, mais lorsqu'une étude nous semble étonnante il peut être utile de vérifier la fiabilité de son échantillon.

### Répliquer les études

Comme vu précédemment, dans tout calcul statistique il y a une marge d'erreur (pour ne pas avoir d'erreur il faudrait un échantillon infini). Si par exemple on accepte une marge d'erreur de 5%, on aura en moyenne 5% de faux positifs (ou de faux négatifs), donc de résultats faux.

C'est pour cela qu'une seule étude n'est jamais une preuve suffisante pour ammener à un consessus scientifique.

C'est aussi pour cette raison que sur de nombreux sujets on peut trouver une petite portion d'études qui montrent l'inverse du consensus. C'est uniquement si cette proportion est significativement plus grande que la marge d'erreur qu'il y a probablement un problème plus important.

<img class="picture" src="{{ site.baseurl }}/assets/images/significant.png" alt="XKCD significant" />

### Procéder en double ou triple aveugle

Imaginez que vous voulez tester l'efficacité d'un nouveau médicament pour les maux de tête. Vous avez déterminé des critères objectivables, sélectionné un large échantillon représentatif de la population et séparé les sujets au hasard en deux groupes, l'un *contrôle* qui reçoit un placébo et l'autre *test* qui reçoit le médicament.

Vous allez voir les sujets du groupe contrôle : "Bonjour Monsieur Bidule ! Voici votre placébo ! Alors, vous avez toujours mal ?".

Non, évidemment, vous avez fait les choses bien et les patients ne savent pas s'ils ont reçu le placébo ou le médicament. On appelle cela une étude en *simple aveugle*.

Pourquoi *simple* ? Parce que vous-mêmes savez si vous administrez le médicament ou le placébo. Or, si vous avez envie de prouver l'efficacité de votre médicament, il y a de fortes chances que vous serez partial dans vos évaluations, même inconsciamment. On appelle ça le *biais de l'observateur*.[^mahtani] [^hrobjartsson]

Pour éviter ça, on a créé le protocole en *double aveugle* : ni le patient ni l'examinateur ne sait si le patient a reçu le médicament ou le placébo.

On a donc besoin d'une tierce personne. Celle-ci va conditionner les médicament et les placébos dans un ordre aléatoire, les identifier par un numéro et garder cette identification secrète jusqu'à la fin de l'étude.

Ensuite l'observateur note les résultats de l'expérience. Par exemple :

* Patient avec le "médicament" n°1 : plus de douleur après 15 minutes
* Patient avec le "médicament" n°2 : plus de douleur après 27 minutes
* Patient avec le "médicament" n°3 : plus de douleur après 6 minutes, apparition de nausées
* Patient avec le "médicament" n°4 : plus de douleur après 20 minutes
* Etc.

Enfin, il fait le lien avec les informations de celui qui a conditionné les produits. Par exemple :

* N°1 = médicament
* N°2 = placébo
* N°3 = placébo
* N°4 = médicament
* Etc.

C'est à ce stade qu'on peut ajoouter un niveau d'aveugle supplémentaire et faire un protocole en *triple aveugle* : on donne les résultats ainsi obtenus à un statisticien, mais sans lui dire quelles données correspondent au placébo ou au médicament.

Le double aveugle est le standard minimum a atteindre pour qu'une étude soit robuste. La patie triple aveugle est moins significative puisque les données collectées sont figées et ne peuvent plus être influencée. Pour cette raison la plupart des études se satisfont du double aveugle.

### Chercher à réfuter

La démarche scientifique commence toujours par tenter de réfuter les nouvelles hypothèses, par chercher l'erreur. En effet, si l'hypothèse est réfutée alors il ne sert à rien de chercher à l'ettayer.

Par exemple : voici 4 cartes à jouer classiques, sans trucage (double face, etc.). Je vous dit que, parmis ces cartes, si une carte a une dame d'un côté alors le dos de la carte est bleu. Quelles cartes devez-vous retourner pour vérfier cette hypothèse ?

<img class="picture" src="{{ site.baseurl }}/assets/images/cards.png" alt="Cartes" />

Il faut retourner :

* La première carte pour vérifier que le dos n'est pas rouge
* La dernière carte pour vérifier qu'il n'y a pas une dame

On cherche à réfuter l'hypothèse.

En effet, si on retournait le deuxième carte, que la couleur du dos soit bleue ou rouge ne nous apprned rien sur l'hypothèse testée.

De même pour la troisième carte. En effet, qu'on y trouve une dame ou non ne nous dit rien sur la validité de l'hypothèse.

## Quelques biais de raisonnement

Un biais de raisonnement, ou biais cognitif, est une distorsion dans le traitement cognitif d'une information qui peuvent conduire à des évaluation faussées, des déductions illogiques et des représentations non rationnelles de la réalité.[^kahneman_2] [^ariely] [^baron]

Avoir connaissance de ces biais et s'en prémunir est très important pour éviter de se faire manipuler et avoir une réflexion aussi proche de la vérité que possible.

Je liste ici quelques-uns des biais les plus courrants.

### Ancrage

**Difficulté à se départir d'une première impression.**

Dans une expérience[^tversky_2] on demandait aux participants d'estimer des quantités en pourcentage (per ex. la part de pays africains à l'ONU) :

* Étape 1 : on fait tourner une roue crantée allant de 10% à 90% devant les participants pour générer un pourcentage au hasard
* Étape 2 : on présente la quantité à estimer (par exemple la part de pays africains à l'ONU)
* Étape 3 : on demande si les participants pensent que la réponse est plus grande ou plus petite que le pourentage généré au hasard
* Étape 4 : on leur demande leur propre estimation

Les résultats montrent que le pourcentage aléatoire influenbçait systématiquement la réponse. Par exemple pour estimer la part de pays africains à l'ONU, un groupe où le pourcentage généré était 10% a repondu en moyenne 25% et un autre où le pourcentage généré etait 65% a répondu en moyenne 45%.

### Biais culturel

**Appréciation de tout phénomène en fonction de ses propres normes culturelles.**[^wiki_biais_culturel]

### Biais de confirmation

**Tendance à noter et à chercher ce qui confirme ses croyances, et à ignorer, ne pas rechercher, ou sous-estimer l'importance de ce qui les contredit.**[^carroll]

<img class="picture" src="{{ site.baseurl }}/assets/images/confirmation.jpg" alt="Biais de confirmation" />

### Biais des coûts irrécupérables

**Persister dans une pratique ou croyance à cause de l'inverstissement déjà réalisé.**[^parayre]

C'est l'application de l'aversion à la perte (attacher plus d'importance à une perte qu'à un gain du même montant) aux coûts passés. Cela s'exprime par exemple lorsque quelqu'un qui a payé sa place de cinéma et se rend compte que le film est mauvais décide de rester voir le film pour "éviter de gaspiller" l'argent qu'il a de toute façon dépensé.

### Biais du survivant

**Se concentrer sur les personnes ou les choses qui ont passé un certain processus de sélection et ignorer ceux qui ne l'ont pas fait, généralement en raison de leur manque de visibilité.**[^shermer]

C'est par exemple le cas lorsqu'on considère que ceux qui donnent des conférences pour éxpliquer les clés de leur succès sont pertinents en oubliant qu'on ne donne la parole qu'à ceux qui ont réussi. Ou quand on croit que "les produits étaient de meilleur qualité à l'époque" en oubliqnt que seuls ceux qui sont de qualité ont pu nous parvenir.

Pour en savoir plus :

<iframe class="video-frame" src="https://www.youtube.com/embed/9jhXy_xW89c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Biais d'attention

**Altération de la perception par des facteurs sélectifs dans l'attention.**

Ce biais est notamment responsable de notre tendance à ignorer les pistes de réflexion qui nous déplaisent.[^baron] [^bar-haim] Il peut aussi renforcer l'effet des syndromes anxieux et dépressifs.[^pfabigan]

### Biais d'optimisme

**Tendance à s'attendre plus à des évènements positifs que négatifs.**[^sharot] [^o-sullivan]

### Biais d'équiprobabilité

**Tendance à croire que chaque processus dans lequel l'aléatoire est impliqué correspond à une distribution juste, avec des probabilités égales pour tout résultat possible.**[^lecoutre] [^lecoutre_2] [^gauvrit]

Par exemple, une expérience menée en 1988[^lecoutre_3] demandait à des lycéens et des étudiants d'estimer, dans la cas d'un lancer de deux dés équilibrés à 6 faces, si les résultats 11 et 12 avaient la même chance de tomber. Près de 60% répondaient que les deux résultats étaient équiprobables (alors que 11 est deux fois plus probable).

### Biais rétrospectif

**Tendance à percevoir les évènements qui se sont déjà produits comme étant plus prévisibles qu'ils ne l'étaient réellement avant qu'ils n'aient lieu.**[^roese_2] [^hoffrage]

On appelle parfois ce biais *l'effet je-le-savais-depuis_le-début*.[^roese]

### Effet Barnum

**Accepter une vague description de la personnalité comme s'appliquant spécifiquement à elle-même.** [^ciccotti]

### Effet Dunning-Kruger

**Sur-estimer ses capacités lorqu'on est sous-qualifié pour un domaine précis.**[^kruger]

Cet effet correspond à ce qu'on nomme parfois "montagne de la stupidité" :

<img class="picture" src="{{ site.baseurl }}/assets/images/dunning_kruger.png" alt="Dunning-Kruger" />

### Effet de halo

**Perception sélective d'informations allant dans le sens d'une première impression que l'on cherche à confirmer.**[^nisbett]

C'est par exemple quand on minimise la gravité des transgressions des personnes dont on a une image positive, quand on cherche avec plus d'application des signes d'intelligence chez ceux qui nous ont renvoyé une bonne première impression, ou quand on juge plus justes les personnes en fonction de leur apparence physique.[^thorndike] [^gibson] [^lachman]

### Effet Pangloss

**Raisonner à rebours vers une cause possible parmi d’autres, généralement vers une position qu'on veut prouver.**

C'est par exemple penser que le fait qu'on retrouve le nombre d'or ($$\varphi = \frac{1 + \sqrt{5}}{2} \approx 1.61803...$$) très souvent dans la nature est la preuve d'une *volonté* (un dieu, une force cosmique, etc.). En réalité le nombre d'or se retrouve car il est est la solution positive à l'équation $$x^2-x-1=0$$ et correspond donc à la résolution optimale des contraintes d'encombrement.[^douady]

C'est aussi penser, en voyant plantée une flèche dans un tronc d'arbre en forêt que l'archer qui l'a envoyée avait la *volonté* de la planter ici.

Dans un autre registre, c'est aussi considérer un évènement *généralement probable mais individuellement improbable* comme improbable. Par exemple imaginez que vous êtes au restaurant et que vous jouez à pile-ou-face en attendant votre repas. Cinq fois de suite vous faites pile. 3.1% de chances qua ça arrive. Incroyable !

En fait, pas vraiment. Imaginez que 1000 autres personnes dans le monde jouent comme vous. Sur toutes ces personnes quelle est probabilité qu'au moins une personne fasse pile cinq fois de suite ? $$1-(1-0.031)^{1000} \approx 99.9999999999978\%$$

### Effet de simple exposition

**Augmenter son adhésion ou sentiment positif par le simple fait d'être exposé à la chose.**[^pennycook] [^zajonc]

### Effet râteau

**Exagérer la régularité du hasard.**[^gilovich]

C'est considérer qu'une répartition aléatoire, dans le temps ou dans l'espace, doit s'étaler selon des intervalles plus réguliers qu'ils ne le sont en réalité.

Par corollaire, cela provoque *l'illusion des séries*, la tendance à percevoir à tort des coïncidences dans des données au hasard.

Par exemple, dans les images suivantes, les points ont été générés aléatoirement dans le carré de gauche mais pas dans celui de droite.

<img class="picture" src="{{ site.baseurl }}/assets/images/clustering.png" alt="Effet râteau" />

### Erreur fondamentale d'attribution

**Accorder une importance disproportionnée aux caractéristiques internes d'une personne (caractère, intentions, émotions, connaissances, etc.) au détriment des facteurs externes et situationnels dans l'analyse du comportement ou du discours d'une personne dans une situation donnée.**[^teb_9]

On parle parfois *d'effet Julien Lepers*, du nom de l'ancien présentateur de l'émission *Question pour un Champion*. En effet beaucoup ont tendance à le considérer comme plus intelligent que les candidats alors qu'il possède les réponses à ses questions sur ses fiches.

### Illusion de connaissance assymétrique

**Perception que sa connaissance des autres est supérieure a la connaissance des autres de soi.**[^pronin]

C'est par exemple croire que le groupe social auquel on appartient connais mieux les autres groupes sociaux que ceux-ci ne le connaissent.[^pronin_2] C'est aussi penser mieux connaitre les autres que ceux-ci nous connaissent.[^pronin]

### Illusion de l'unique invulnérabilité

**Reconnaitre l'impact des biais sur le jugement des autres, tout en l'omettant ou le minimisant sur son propre jugement.**[^pronin_3]

### Perception sélective

**Tendance à interpréter de manière sélective ce que l'on observe selon nos intérêts, notre situation sociale, notre expérience et nos attitudes.**[^robbins]

## Quelques arguments falalcieux

Un *argument fallacieux* est un raisonnement invalide qui peut pourtant avoir une apparence de validité logique.

J'ai déjà écrit un article dédié et une brève sur le sujet. je vous encourage à les lire.

Article complet : [Quelques arguments fallacieux]({{ site.baseurl }}{% post_url rationalite/2020-06-17-quelques-arguments-fallacieux %})
{: .read-full-info}

Brève : [[En bref] Arguments Fallacieux]({{ site.baseurl }}/bref/arguments-fallacieux)
{: .read-short-info}

## S'entrainer

<!-- TODO -->
<div class="wip-warning">
    <p>🚧</p>
    <p class="bold">À faire</p>
</div>

Place maintenant à la pratique, sur des cas inventés puis, dans la section suivante, sur des cas réels.

Je propose quelques exercices, dont les réponses ne sont pas exhaustives mais pointent quelques problèmes et donnent des pistes de réflexion.

### Exercice 1

#### Question

Lors d'un repas, un ami vous raconte la chose suivante : « alors que chaque hiver, je suis sujet à des grippes, cette année j'ai suivi les conseils de mon pharmacien, et j'ai pris de l'homéopathie, en l'occurrence Oscillococcinum. Et figure-toi que je n'ai pas été malade ! C'est fou, non ? Ma cousine, pareil. Pas un rhume, rien ! Alors on peut dire ce qu'on veut, ça marche. Et pour ceux pour qui ça ne marche pas, au moins ça ne leur fait pas de mal. De toute façon, c'est toujours mieux que de prendre des antibiotiques. »

Quelle analyse critique pouvez-vous faire ?

#### Réponse

Il y a une confussion entre grippe (influenza) et rhume (rhinopharyngite) qui sont des maladies différentes.[^eccles]

Le "test" est aussi baisé puisqu'il n'y a pas de vraiation seule du paramètre médicament. En effet, d'autres facteurs qui peuvent expliquer l'absence de symptômes cette année : meilleure réponse immunitaire, exposition à une souche virale différente, meilleure hygiène, facteurs de transmissions différents, etc.

Il y a ausi une généralisation abusive. Conclure "ca marche" sur la base de deux témoignages individuels relevant d'une expérience non décisive est fautif.

Dire "au moins ça ne leur fait pas de mal" n'est pas ettayé par des preuves. Tout ce qui a un effet peut avoir un effet négatif en fonction de la dose et du contexte.

Enfin, la grippe et le rhume sont tous deux causés par des virus et les antibiotiques n'agissent que sur les bactéries.

### Exercice 2

#### Question

Vous êtes le chef de la police d'une ville d'un million d'habitants et vous savez qu'un habitant sur mille est un criminel. Vous décidez d'installer un nouveau dispositif de reconnaissance faciale pour les détecter.A chaque fois qu'un visage est filmé, le système dit s'il s'agit où non d'un criminel. Il n'est pas fiable à 100%, mais sa marge d'erreur n'est que de 1% (1 fois sur 100 il déctera un innocent comme criminel ou un criminel comme innocent).

Si une personne prise au hasard parmi les habitants déclenche une alerte, quelle est la chance que ce soit un criminel ?

#### Réponse

La réponse n'est évidemment pas 99%.

Il ne faut pas oublier que seule une personne sur mille est un criminel, soit 0,1% de la population.

Quelle est la probabilité que l’alerte se déclenche pour un citoyen pris au hasard ? Elle vaut 1% fois la probabilité d'être innocent plus 99% fois la probabilité d'être un criminel, soit 1,098%

Mais ce qu'on cherche à savoir c'est la probabilité qu'une personne ayant déclenché l'alerte soit effectivement un criminel. 

Notons $$A$$ l'hypothèse selon laquelle l'alerte s'est déclenchée et $$C$$ le fait qu'une personne soit un criminel. On cherche donc $$P(C \vert A)$$, la probabilité qu'une parsonne soit un criminer sachant que l'alerte s'est déclenchée.

On utilise le théorème de Bayes :

$$P(C \vert A) = \dfrac{P(A \vert C) \cdot P(C)}{P(A)}$$

Avec :

* $$P(A \vert C)$$ est la probabilité que l'alerte se déclenche sachant que la personne est un criminel, donc 99%
* $$P(C)$$ est la probabilité qu'une personne soit un criminel, donc 0,1%
* $$P(A)$$ est la probabilité que l'alerte se déclenche, pour un citoyen au hasard, donc 1,098%

On a donc :

$$P(C \vert A) = \dfrac{0.99 \cdot 0.001}{0.01098} \approx 9\%$$

Ainsi malgré une fiabilité à 99%, en cas d'alerte il n'y a que 9 chances sur 100 que la personne soit un criminel.

### Exercice 3

#### Question



## Quelques applications concrètes

<!-- TODO -->
<div class="wip-warning">
    <p>🚧</p>
    <p class="bold">À faire</p>
</div>

## TODO

<!-- TODO -->
<div class="wip-warning">
    <p>🚧</p>
    <p class="bold">À faire</p>
</div>

* les maths/stats/proba de base et quelques erreurs courrantes (par ex. pb de Monty Hall ou des 2 enfants de Lê)
* quelques brèves
* méthode scientifique : d'abord chercher à réfuter
* double aveugle, etc.

## Quelques ressources pour aller plus loin

<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PL8kpTYGNfAcbcbHO_jt9NYHP1KefT4Nfp" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

## Références

[^rationality_less_wrong]: Yudkowsky, E. (2009, mars 16). *What Do We Mean By "Rationality"? - LessWrong 2.0*. Consulté le 16 juillet 2020, à l'adresse <https://www.lesswrong.com/s/5g5TkQTe9rmPS5vvM/p/RcZCwxFiZzE6X7nsv>

[^ennis_1]: Ennis, R. H. (2015). *Critical Thinking : A Streamlined Conception*. In M. Davies & R. Barnett (Éds.), *The Palgrave Handbook of Critical Thinking in Higher Education* (p. 31‑47). Palgrave Macmillan US. <https://doi.org/10.1057/9781137378057_2>

[^tlfi_raison]: Analyse et Traitement Informatique de la Langue Française (Éd.). (s. d.). *Raison*. Dans *Trésor de la Langue Française informatisé*. Consulté à l'adresse <https://www.cnrtl.fr/definition/raison>

[^tlfi_reflexion]: Analyse et Traitement Informatique de la Langue Française (Éd.). (s. d.). *Réflexion*. Dans *Trésor de la Langue Française informatisé*. Consulté à l'adresse <https://www.cnrtl.fr/definition/reflexion>

[^lipman_1]: Lipman, M. (2003). *Thinking in Education* (2ᵉ éd.). Cambridge University Press. <https://doi.org/10.1017/CBO9780511840272>

[^mcpeck_1]: McPeck, J. E. (2017). *Critical thinking and education* (Routledge).

[^monvoisin_these]: Monvoisin, R. (2007). *Pour une didactique de l'esprit critique* [Université Grenoble 1 – Joseph Fourier]. <http://www.unice.fr/zetetique/articles/RM_Doctorat_Zetetique_et_medias.pdf>

[^tlfi_rationnel]: Analyse et Traitement Informatique de la Langue Française (Éd.). (s. d.). *Rationnel*. Dans *Trésor de la Langue Française informatisé*. Consulté à l'adresse <https://www.cnrtl.fr/definition/rationnel>

[^wiki_scepticisme]: *Scepticisme scientifique*. (2020, 4 juillet). Dans Wikipédia. <https://fr.wikipedia.org/wiki/Scepticisme_scientifique>

[^herodote_vinci]: Chenal, Y. (2020, 16 mai). *Léonard de Vinci (1452 - 1519)*. Hérodote. <https://www.herodote.net/Le_genie_paradoxal-synthese-546.php>

[^armitt_potter]: *Beatrix Potter*. (s. d.). Armitt Museum & Library. Consulté 21 juillet 2020, à l'adresse <http://armitt.com/armitt_website/beatrix-potter/>

[^nga_morse]: *Samuel F. B. Morse*. (s. d.). National Gallery of Art. Consulté 21 juillet 2020, à l'adresse <https://www.nga.gov/collection/artist-info.1737.html>

[^ms_lamarr]: O'Brien, E. (2017, 27 octobre). *5 facts about Hedy Lamarr, star, inventor, wartime code maker*. Massive Science. <https://massivesci.com/articles/hedy-lamarr-inventor-world-war-movie-star-frequency/>

[^sa_queen]: Devillard, A. (2014, 10 novembre). *Queen, trois scientifiques pour un quatuor de rock*. Sciences et Avenir. <https://www.sciencesetavenir.fr/insolite/queen-trois-scientifiques-pour-un-quatuor-de-rock_{37226}>

[^panksepp]: Panksepp, J. (2005). *Affective neuroscience : The foundations of human and animal emotions*. Oxford Univ. Press.

[^damasio]: Damasio, A. R. (1998). *Emotion in the perspective of an integrated nervous system*. Brain Research Reviews, 26(2‑3), 83‑86. <https://doi.org/10.1016/S0165-0173(97)00064-7>

[^ekman]: Ekman, P., & Davidson, R. J. (Éds.). (1994). *The nature of emotion : Fundamental questions*. Oxford University Press.

[^cabanac]: Cabanac, M. (2002). *What is emotion?* Behavioural Processes, 60(2), 69‑83. <https://doi.org/10.1016/S0376-6357(02)00078-5>

[^emory]: Emory, M. (2018, 6 juin). *On Fear, Emotions, and Memory : An Interview with Dr. Joseph LeDoux*. Brain World. <https://brainworldmagazine.com/on-fear-emotions-and-memory-an-interview-with-dr-joseph-ledoux/2/>

[^kirman]: Kirman, A., Livet, P., & Teschl, M. (2010). *Rationality and emotions*. Philosophical Transactions of the Royal Society B: Biological Sciences, 365(1538), 215‑219. <https://doi.org/10.1098/rstb.2009.0194>

[^pfister]: Pfister, H.-R., & Böhm, G. (2008). *The multiplicity of emotions: A framework of emotional functions in decision making*. Judgment and Decision Making, 3(1), 5–17.

[^andrade]: Andrade, E. B., & Ariely, D. (2009). *The enduring impact of transient emotions on decision making*. Organizational Behavior and Human Decision Processes, 109(1), 1‑8. <https://doi.org/10.1016/j.obhdp.2009.02.003>

[^gigerenzer]: Gigerenzer, G. (2003, 29 mars). *Smart Heuristics*. Edge. <https://www.edge.org/conversation/gerd_gigerenzer-smart-heuristics>

[^kahneman]: Kahneman, D. (2011). *Thinking, fast and slow* (1st ed). Farrar, Straus and Giroux.

[^evans]: Evans, J. St. B. T. (2003). *In two minds : Dual-process accounts of reasoning*. Trends in Cognitive Sciences, 7(10), 454‑459. <https://doi.org/10.1016/j.tics.2003.08.012>

[^frederick]: Frederick, S. (2005). *Cognitive Reflection and Decision Making*. Journal of Economic Perspectives, 19(4), 25‑42. <https://doi.org/10.1257/089533005775196732>

[^galef_vulcan]: Thought Process. (2013, 17 août). *The Straw Vulcan, Julia Galef Skepticon 4* [Vidéo]. YouTube. <https://www.youtube.com/watch?v=Fv1nMc-k0N4>

[^blanchette]: Blanchette, I., & Richards, A. (2010). *The influence of affect on higher level cognition : A review of research on interpretation, judgement, decision making and reasoning*. Cognition & Emotion, 24(4), 561‑595. <https://doi.org/10.1080/02699930903132496>

[^trofimova]: Trofimova, I. (2018). *Functionality versus dimensionality in psychological taxonomies, and a puzzle of emotional valence*. Philosophical Transactions of the Royal Society B: Biological Sciences, 373(1744), 20170167. <https://doi.org/10.1098/rstb.2017.0167>

[^angie]: Angie, A. D., Connelly, S., Waples, E. P., & Kligyte, V. (2011). *The influence of discrete emotions on judgement and decision-making : A meta-analytic review*. Cognition & Emotion, 25(8), 1393‑1422. <https://doi.org/10.1080/02699931.2010.550751>

[^monvoisin_pinsault]: Pinsault, N., & Monvoisin, R. (2014). *Tout ce que vous n'avez jamais voulu savoir sur les thérapies manuelles*. Presses universitaires de Grenoble.

[^geldard]: Geldard, F. A., & Sherrick, C. E. (1972). *The Cutaneous « Rabbit » : A Perceptual Illusion*. Science, 178(4057), 178‑179. <https://doi.org/10.1126/science.178.4057.178>

[^bremer]: Bremer, C. D., Pittenger, J. B., Warren, R., & Jenkins, J. J. (1977). *An Illusion of Auditory Saltation Similar to the Cutaneous « Rabbit »*. The American Journal of Psychology, 90(4), 645. <https://doi.org/10.2307/1421738>

[^flach]: Flach, R., & Haggard, P. (2006). *The cutaneous rabbit revisited*. Journal of Experimental Psychology: Human Perception and Performance, 32(3), 717‑732. <https://doi.org/10.1037/0096-1523.32.3.717>

[^helson]: Helson, H., & King, S. M. (1931). *The tau effect : An example of psychological relativity*. Journal of Experimental Psychology, 14(3), 202‑217. <https://doi.org/10.1037/h0071164>

[^russo]: Russo, G., & Dellantonio, A. (1989). *Influence of Phenomenal Time on Perceived Space*. Perceptual and Motor Skills, 68(3), 971‑984. <https://doi.org/10.2466/pms.1989.68.3.971>

[^barnett-cowan]: Barnett-Cowan, M. (2010). *An Illusion You Can Sink Your Teeth into : Haptic Cues Modulate the Perceived Freshness and Crispness of Pretzels*. Perception, 39(12), 1684‑1686. <https://doi.org/10.1068/p6784>

[^robles-de-la-torre]: Robles-De-La-Torre, G., & Hayward, V. (2001). *Force can overcome object geometry in the perception of shape through active touch*. Nature, 412(6845), 445‑448. <https://doi.org/10.1038/35086588>

[^tversky]: Tversky, A., & Kahneman, D. (1981). *The framing of decisions and the psychology of choice*. Science, 211(4481), 453‑458. <https://doi.org/10.1126/science.7455683>

[^benedetti]: Benedetti, F. (2002). *How the Doctor's Words Affect the Patient's Brain*. Evaluation & the Health Professions, 25(4), 369‑386. <https://doi.org/10.1177/0163278702238051>

[^wiseman]: Wiseman, R., & Greening, E. (2005). *It's still bending : Verbal suggestion and alleged psychokinetic ability*. British Journal of Psychology, 96(1), 115‑127. <https://doi.org/10.1348/000712604X15428>

[^gentner]: Gentner, D., & Loftus, E. F. (1979). *Integration of Verbal and Visual Information as Evidenced by Distortions in Picture Memory*. The American Journal of Psychology, 92(2), 363. <https://doi.org/10.2307/1421930>

[^montel]: Montel, S. (2016). *11 grandes notions de neuropsychologie*. Dunod.

[^baddeley]: Baddeley, A. (2007). *Working Memory, Thought, and Action*. Oxford University Press. <https://doi.org/10.1093/acprof:oso/9780198528012.001.0001>

[^tulving]: Tulving, E., & Schacter, D. (1990). *Priming and human memory systems*. Science, 247(4940), 301‑306. <https://doi.org/10.1126/science.2296719>

[^cole]: Cole, W. G., & Loftus, E. F. (1979). *Incorporating New Information into Memory*. The American Journal of Psychology, 92(3), 413. <https://doi.org/10.2307/1421560>

[^loftus]: Loftus, E. F., Miller, D. G., & Burns, H. J. (1978). *Semantic integration of verbal information into a visual memory*. Journal of Experimental Psychology: Human Learning and Memory, 4(1), 19‑31. <https://doi.org/10.1037/0278-7393.4.1.19>

[^loftus_2]: Loftus, E. F. (1979). *Reactions to blatantly contradictory information*. Memory & Cognition, 7(5), 368‑374. <https://doi.org/10.3758/BF03196941>

[^ramirez]: Ramirez, S., Liu, X., Lin, P.-A., Suh, J., Pignatelli, M., Redondo, R. L., Ryan, T. J., & Tonegawa, S. (2013). Creating a False Memory in the Hippocampus. Science, 341(6144), 387‑391. <https://doi.org/10.1126/science.1239073>

[^bjorklund]: Bjorklund, D. F. (2012). *False-memory creation in children and adults : Theory, research, and implications*. Psychology Press.

[^conway]: Conway, M. A. (Éd.). (1997). *Recovered Memories and False Memories*. Oxford University Press. <https://doi.org/10.1093/med:psych/9780198523864.001.0001>

[^roediger]: Roediger, H. L., & Marsh, E. J. (2009). *False memory*. Scholarpedia, 4(8), 3858. <https://doi.org/10.4249/scholarpedia.3858>

[^schacter]: Schacter, D. L., & Curran, T. (1995). *The Cognitive Neuroscience of False Memories*. Psychiatric Annals, 25(12), 726‑730. <https://doi.org/10.3928/0048-5713-19951201-08>

[^loftus_3]: Loftus, E. F. (2005). *Planting misinformation in the human mind : A 30-year investigation of the malleability of memory*. Learning & Memory, 12(4), 361‑366. <https://doi.org/10.1101/lm.94705>

[^roediger_2]: Roediger, H. L., & McDermott, K. B. (1995). *Creating false memories : Remembering words not presented in lists*. Journal of Experimental Psychology: Learning, Memory, and Cognition, 21(4), 803‑814. <https://doi.org/10.1037/0278-7393.21.4.803>

[^roediger_3]: Roediger, H. L., Watson, J. M., McDermott, K. B., & Gallo, D. A. (2001). *Factors that determine false recall : A multiple regression analysis*. Psychonomic Bulletin & Review, 8(3), 385‑407. <https://doi.org/10.3758/BF03196177>

[^loftus_4]: Loftus, E. F., & Pickrell, J. E. (1995). *The Formation of False Memories*. Psychiatric Annals, 25(12), 720‑725. <https://doi.org/10.3928/0048-5713-19951201-07>

[^payne]: Payne, J. D., Schacter, D. L., Propper, R. E., Huang, L.-W., Wamsley, E. J., Tucker, M. A., Walker, M. P., & Stickgold, R. (2009). *The role of sleep in false memory formation*. Neurobiology of Learning and Memory, 92(3), 327‑334. <https://doi.org/10.1016/j.nlm.2009.03.007>

[^rubin]: Rubin, D. C., Schrauf, R. W., & Greenberg, D. L. (2003). *Belief and recollection of autobiographical memories*. Memory & Cognition, 31(6), 887‑901. <https://doi.org/10.3758/BF03196443>

[^tlfi_inference]: Analyse et Traitement Informatique de la Langue Française (Éd.). (s. d.). *Inférence*. Dans *Trésor de la Langue Française informatisé*. Consulté à l'adresse <https://www.cnrtl.fr/definition/inference>

[^galef_diag]: Julia Galef. (2015, 16 juillet). *A visual guide to Bayesian thinking* [Vidéo]. YouTube. <https://www.youtube.com/watch?v=BrK7X_XlGB8>

[^antidote_preuve]: Druide informatique (Éd.) (2019) *Preuve*. Dans *Dictionnaire de définitions*, Antidote 10, version 3

[^afis_preuve]: Association Française pour l'Information Scientifique. (2019, 6 mars). *La qualité de la preuve en médecine*. Consulté 15 juin 2020, à l'adresse <https://www.pseudo-sciences.org/La-qualite-de-la-preuve-en-medecine>

[^grades_burns]: Burns, P. B., Rohrich, R. J., & Chung, K. C. (2011). *The Levels of Evidence and Their Role in Evidence-Based Medicine: Plastic and Reconstructive Surgery*, 128(1), 305‑310. <https://doi.org/10.1097/PRS.0b013e318219c171>

[^grades_bjm]: *Grading quality of evidence and strength of recommendations*. (2004). BMJ, 328(7454), 1490. <https://doi.org/10.1136/bmj.328.7454.1490>

[^grades_hadorn]: Hadorn, D. C., Baker, D., Hodges, J. S., & Hicks, N. (1996). *Rating the quality of evidence for clinical practice guidelines*. Journal of Clinical Epidemiology, 49(7), 749‑754. <https://doi.org/10.1016/0895-4356(96)00019-4>

[^grades_petrisor]: Petrisor, B., & Bhandari, M. (2007). *The hierarchy of evidence : Levels and grades of recommendation*. Indian Journal of Orthopaedics, 41(1), 11. <https://doi.org/10.4103/0019-5413.30519>

[^grades_wilson]: Wilson, M. C. (1995). Users' Guides to the Medical Literature : *VIII. How to Use Clinical Practice Guidelines B. What Are the Recommendations and Will They Help You in Caring for Your Patients?* JAMA, 274(20), 1630. <https://doi.org/10.1001/jama.1995.03530200066040>

[^grades_has]: Haute Autorité de Santé. (2013, avril). *Niveau de preuve et gradation des recommandations de bonne pratique*. Consulté à l'adresse <https://www.has-sante.fr/upload/docs/application/pdf/2013-06/etat_des_lieux_niveau_preuve_gradation.pdf>

[^stanovich]: Stanovich, K. E., & West, R. F. (2008). On the relative independence of thinking biases and cognitive ability. Journal of Personality and Social Psychology, 94(4), 672‑695. <https://doi.org/10.1037/0022-3514.94.4.672>

[^beauvoisine]: TEDx Beauvoisine. (2019, 25 avril). *Méfiez-vous des conférences TED et TEDx ?* [Vidéo]. YouTube. <https://www.youtube.com/watch?v=Y8fO3e8P0_A>

[^kahneman_2]: Kahneman, D., & Tversky, A. (1972). *Subjective probability : A judgment of representativeness.* Cognitive Psychology, 3(3), 430‑454. <https://doi.org/10.1016/0010-0285(72)90016-3>

[^ariely]: Ariely, D. (2008). *Predictably irrational : The hidden forces that shape our decisions* (1st ed). Harper.

[^baron]: Baron, J. (2008). *Thinking and deciding* (4th ed). Cambridge University Press.

[^murphy]: Murphy, G., Loftus, E. F., Grady, R. H., Levine, L. J., & Greene, C. M. (2019). *False Memories for Fake News During Ireland's Abortion Referendum*. Psychological Science, 30(10), 1449‑1459. <https://doi.org/10.1177/0956797619864887>

[^bar-haim]: Bar-Haim, Y., Lamy, D., Pergamin, L., Bakermans-Kranenburg, M. J., & van IJzendoorn, M. H. (2007). *Threat-related attentional bias in anxious and nonanxious individuals : A meta-analytic study*. Psychological Bulletin, 133(1), 1‑24. <https://doi.org/10.1037/0033-2909.133.1.1>

[^pfabigan]: Pfabigan, D. M., & Tran, U. S. (2015). *Behavioral and physiological bases of attentional biases : Paradigms, participants, and stimuli*. Frontiers Media SA. <http://journal.frontiersin.org/researchtopic/1845/behavioral-and-physiological-bases-of-attentional-biases-paradigms-participants-and-stimuli>

[^sharot]: Sharot, T. (2011). *The optimism bias*. Current Biology, 21(23), R941‑R945. <https://doi.org/10.1016/j.cub.2011.10.030>

[^o-sullivan]: O'sullivan, O. P. (2015). *The Neural Basis of Always Looking on the Bright Side*.

[^ciccotti]: Ciccotti, S. (2008). *L'effet Barnum*. Revue électronique de Psychologie Sociale, 2, 27‑31. <https://psychologiescientifique.org/wp-content/uploads/2018/02/REPS2.pdf>

[^wiki_biais_culturel]: *Biais culturel*. (2019, 28 août). Dans Wikipédia. <https://fr.wikipedia.org/wiki/Biais_culturel>

[^kruger]: Kruger, J., & Dunning, D. (1999). *Unskilled and unaware of it : How difficulties in recognizing one's own incompetence lead to inflated self-assessments*. Journal of Personality and Social Psychology, 77(6), 1121‑1134. <https://doi.org/10.1037/0022-3514.77.6.1121>

[^robbins]: Robbins, S. P., & Judge, T. (2019). *Organizational behavior* (18th edition). Pearson.

[^postman]: Postman, L., & Phillips, L. W. (1965). *Short-term Temporal Changes in Free Recall*. Quarterly Journal of Experimental Psychology, 17(2), 132‑138. <https://doi.org/10.1080/17470216508416422>

[^tversky_2]: Tversky, A., & Kahneman, D. (1974). *Judgment under Uncertainty : Heuristics and Biases*. Science, 185(4157), 1124‑1131. <https://doi.org/10.1126/science.185.4157.1124>

[^pennycook]: Pennycook, G., Cannon, T. D., & Rand, D. G. (2018). *Prior exposure increases perceived accuracy of fake news*. Journal of Experimental Psychology: General, 147(12), 1865‑1880. <https://doi.org/10.1037/xge0000465>

[^zajonc]: Zajonc, R. B. (1968). *Attitudinal effects of mere exposure*. Journal of Personality and Social Psychology, 9(2, Pt.2), 1‑27. <https://doi.org/10.1037/h0025848>

[^parayre]: Parayre, R. (1995). *The strategic implications of sunk costs : A behavioral perspective*. Journal of Economic Behavior & Organization, 28(3), 417‑442. <https://doi.org/10.1016/0167-2681(95)00045-3>

[^shermer]: Shermer, M. (2014). *Surviving Statistics*. Scientific American, 311(3), 94‑94. <https://doi.org/10.1038/scientificamerican0914-94>

[^lecoutre]: Lecoutre, M.-P. (1985). *Jugements probabilistes chez des adultes : Pratique des jeux de hasard et formation en théorie des probabilités*. Bulletin de Psychologie, 372, 891‑900. <https://www.researchgate.net/publication/265642780_Jugements_probabilistes_chez_des_adultes_Pratique_des_jeux_de_hasard_et_formation_en_theorie_des_probabilites>

[^lecoutre_2]: Lecoutre, Marie-Paule. (2014). *Effet d'informations de nature combinatoire et de nature fréquentielle sur les jugements probabilistes*.

[^lecoutre_3]: Lecoutre, M.-P., & Durand, J.-L. (1988). *Jugements probabilistes et modeles cognitifs : Etude d'une situation aleatoire*. Educational Studies in Mathematics, 19(3), 357‑368. <https://doi.org/10.1007/BF00312452>

[^gauvrit]: Gauvrit, N., & Morsanyi, K. (2014). *The equiprobability bias from a mathematical and psychological perspective*. Advances in cognitive psychology, 10(4), 119–130. <https://doi.org/10.5709/acp-0163-9>

[^carroll]: Carroll, R. T. (2016, 15 juin). *Confirmation bias*. The Skeptik's Dictionary. <http://www.skepdic.com/confirmbias.html>

[^roese]: Roese, N. J. (2012, 6 septembre). *‘I Knew It All Along… Didn't I ? ' – Understanding Hindsight Bias*. Association for Psychological Science. <https://www.psychologicalscience.org/news/releases/i-knew-it-all-along-didnt-i-understanding-hindsight-bias.html>

[^roese_2]: Roese, N. J., & Vohs, K. D. (2012). *Hindsight Bias*. Perspectives on Psychological Science, 7(5), 411‑426. <https://doi.org/10.1177/1745691612454303>

[^hoffrage]: Hoffrage, U., & Pohl, R. (2003). *Research on hindsight bias : A rich past, a productive present, and a challenging future*. Memory, 11(4‑5), 329‑335. <https://doi.org/10.1080/09658210344000080>

[^nisbett]: Nisbett, R. E., & Wilson, T. D. (1977). *The halo effect : Evidence for unconscious alteration of judgments*. Journal of Personality and Social Psychology, 35(4), 250‑256. <https://doi.org/10.1037/0022-3514.35.4.250>

[^thorndike]: Thorndike, E. L. (1920). *A constant error in psychological ratings*. Journal of Applied Psychology, 4(1), 25‑29. <https://doi.org/10.1037/h0071663>

[^gibson]: Gibson, J. L., & Gore, J. S. (2016). *Is He a Hero or a Weirdo? How Norm Violations Influence the Halo Effect*. Gender Issues, 33(4), 299‑310. <https://doi.org/10.1007/s12147-016-9173-6>

[^lachman]: Lachman, S. J., & Bass, A. R. (1985). *A Direct Study of Halo Effect*. The Journal of Psychology, 119(6), 535‑540. <https://doi.org/10.1080/00223980.1985.9915460>

[^gilovich]: Gilovich, T. (1991). *How we know what isn't so : The fallibility of human reason in everyday life*. Free Press.

[^teb_9]: La Tronche en Biais. (2018, 3 octobre). L'erreur fondamentale d'attribution [Vidéo]. YouTube. <https://www.youtube.com/watch?v=HIbgaPslcSw>

[^pronin]: Pronin, E., Kruger, J., Savtisky, K., & Ross, L. (2001). *You don't know me, but I know you : The illusion of asymmetric insight*. Journal of Personality and Social Psychology, 81(4), 639‑656. <https://doi.org/10.1037/0022-3514.81.4.639>

[^pronin_2]: Pronin, E., Fleming, J. J., & Steffel, M. (2008). *Value revelations : Disclosure is in the eye of the beholder*. Journal of Personality and Social Psychology, 95(4), 795‑809. <https://doi.org/10.1037/a0012710>

[^pronin_3]: Pronin, E., Lin, D. Y., & Ross, L. (2002). *The Bias Blind Spot : Perceptions of Bias in Self Versus Others*. Personality and Social Psychology Bulletin, 28(3), 369‑381. <https://doi.org/10.1177/0146167202286008>

[^fontenelle]: Le Bouyer de Fontenelle, B. (1687). *Histoire des oracles*. Michel Brunet. <https://gallica.bnf.fr/ark:/12148/bpt6k10412238>

[^blasi]: Blasi, Z. D., Harkness, E., Ernst, E., Georgiou, A., & Kleijnen, J. (2001). *Influence of context effects on health outcomes : A systematic review*. The Lancet, 357(9258), 757‑762. <https://doi.org/10.1016/S0140-6736(00)04169-6>

[^marks]: Marks, D. F. (1986). *Investigating the paranormal*. Nature, 320(6058), 119‑124. <https://doi.org/10.1038/320119a0>

[^hines]: Hines, T. (2003). *Pseudoscience and the paranormal* (2nd ed). Prometheus Books.

[^regal]: Regal, B. (2009). *Pseudoscience : A critical encyclopedia*. Greenwood Press.

[^vogt]: Vogt, E. Z., & Hyman, R. (1979). *Water witching, U.S.A* (2d ed). University of Chicago Press.

[^hauteurs]: Hauteurs UGA. (2017, 2 octobre). *Cours 5 Épisode 3 - Protocoles expérimentaux (3)* [Vidéo]. YouTube. <https://www.youtube.com/watch?v=0cZ-Tpb8OQU>

[^mahtani]: Mahtani, K., Spencer, E. A., Brassey, J., & Heneghan, C. (2018). *Catalogue of bias : Observer bias*. BMJ Evidence-Based Medicine, 23(1), 23‑24. <https://doi.org/10.1136/ebmed-2017-110884>

[^hrobjartsson]: Hrobjartsson, A., Thomsen, A. S. S., Emanuelsson, F., Tendal, B., Hilden, J., Boutron, I., Ravaud, P., & Brorson, S. (2012). *Observer bias in randomised clinical trials with binary outcomes : Systematic review of trials with both blinded and non-blinded outcome assessors*. BMJ, 344(feb27 2), e1119‑e1119. <https://doi.org/10.1136/bmj.e1119>

[^douady]: Douady, S., & Couder, Y. (1993, janvier). *La physique des spirales végétales*. La Recherche, 28(250). <https://www.larecherche.fr>

[^eccles]: Eccles, R. (2005). *Understanding the symptoms of the common cold and influenza*. The Lancet Infectious Diseases, 5(11), 718‑725. <https://doi.org/10.1016/S1473-3099(05)70270-X>

